begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_package
DECL|package|antlr
package|package
name|antlr
package|;
end_package

begin_comment
comment|/* ANTLR Translator Generator  * Project led by Terence Parr at http://www.jGuru.com  * Software rights: http://www.antlr.org/license.html  *  * $Id$  */
end_comment

begin_comment
comment|//
end_comment

begin_comment
comment|// ANTLR C# Code Generator by Micheal Jordan
end_comment

begin_comment
comment|//                            Kunle Odutola       : kunle UNDERSCORE odutola AT hotmail DOT com
end_comment

begin_comment
comment|//                            Anthony Oguntimehin
end_comment

begin_comment
comment|//
end_comment

begin_comment
comment|// With many thanks to Eric V. Smith from the ANTLR list.
end_comment

begin_comment
comment|//
end_comment

begin_comment
comment|// HISTORY:
end_comment

begin_comment
comment|//
end_comment

begin_comment
comment|// 17-May-2002 kunle    Fixed bug in OctalToUnicode() - was processing non-Octal escape sequences
end_comment

begin_comment
comment|//                      Also added namespace support based on Cpp version.
end_comment

begin_comment
comment|// 07-Jun-2002 kunle    Added Scott Ellis's _saveIndex creation optimizations
end_comment

begin_comment
comment|// 09-Sep-2002 richardN Richard Ney's bug-fix for literals table construction.
end_comment

begin_comment
comment|//                      [ Hashtable ctor needed instance of hash code provider not it's class name. ]
end_comment

begin_comment
comment|// 17-Sep-2002 kunle&  Added all Token ID definitions as data member of every Lexer/Parser/TreeParser
end_comment

begin_comment
comment|//             AOg      [ A by-product of problem-solving phase of the hetero-AST changes below
end_comment

begin_comment
comment|//                        but, it breaks nothing and restores "normal" ANTLR codegen behaviour. ]
end_comment

begin_comment
comment|// 19-Oct-2002 kunle&  Completed the work required to support heterogenous ASTs (many changes)
end_comment

begin_comment
comment|//             AOg&
end_comment

begin_comment
comment|//             michealj
end_comment

begin_comment
comment|// 14-Nov-2002 michealj Added "initializeASTFactory()" to support flexible ASTFactory initialization.
end_comment

begin_comment
comment|//						[ Thanks to Ric Klaren - for suggesting it and implementing it for Cpp. ]
end_comment

begin_comment
comment|// 18-Nov-2002 kunle    Added fix to make xx_tokenSet_xx names CLS compliant.
end_comment

begin_comment
comment|// 01-Dec-2002 richardN Patch to reduce "unreachable code" warnings
end_comment

begin_comment
comment|// 01-Dec-2002 richardN Fix to generate correct TreeParser token-type classnames.
end_comment

begin_comment
comment|// 12-Jan-2003 kunle& Generated Lexers, Parsers and TreeParsers now support ANTLR's tracing option.
end_comment

begin_comment
comment|//             michealj
end_comment

begin_comment
comment|// 12-Jan-2003 kunle    Fixed issue where initializeASTFactory() was generated when "buildAST=false"
end_comment

begin_comment
comment|// 14-Jan-2003 AOg      initializeASTFactory(AST factory) method was modifying the Parser's "astFactory"
end_comment

begin_comment
comment|//                      member rather than it's own "factory" parameter. Fixed.
end_comment

begin_comment
comment|// 18-Jan-2003 kunle& Fixed reported issues with ASTFactory create() calls for hetero ASTs
end_comment

begin_comment
comment|//             michealj - code generated for LEXER token with hetero-AST option specified does not compile
end_comment

begin_comment
comment|//                      - code generated for imaginary tokens with hetero-AST option specified uses
end_comment

begin_comment
comment|//                        default AST type
end_comment

begin_comment
comment|//                      - code generated for per-TokenRef hetero-AST option specified does not compile
end_comment

begin_comment
comment|// 18-Jan-2003 kunle    initializeASTFactory(AST) method is now a static public member
end_comment

begin_comment
comment|// 18-May-2003 kunle    Changes to address outstanding reported issues::
end_comment

begin_comment
comment|//                      - Fixed reported issues with support for case-sensitive literals
end_comment

begin_comment
comment|//                      - antlr.SemanticException now imported for all Lexers.
end_comment

begin_comment
comment|//                        [ This exception is thrown on predicate failure. ]
end_comment

begin_comment
comment|// 12-Jan-2004 kunle    Added fix for reported issue with un-compileable generated lexers
end_comment

begin_comment
comment|//
end_comment

begin_comment
comment|//
end_comment

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Enumeration
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Hashtable
import|;
end_import

begin_import
import|import
name|antlr
operator|.
name|collections
operator|.
name|impl
operator|.
name|BitSet
import|;
end_import

begin_import
import|import
name|antlr
operator|.
name|collections
operator|.
name|impl
operator|.
name|Vector
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintWriter
import|;
end_import

begin_comment
comment|//SAS: changed for proper text file io
end_comment

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileWriter
import|;
end_import

begin_comment
comment|/** Generates MyParser.cs, MyLexer.cs and MyParserTokenTypes.cs */
end_comment

begin_class
DECL|class|CSharpCodeGenerator
specifier|public
class|class
name|CSharpCodeGenerator
extends|extends
name|CodeGenerator
block|{
comment|// non-zero if inside syntactic predicate generation
DECL|field|syntacticPredLevel
specifier|protected
name|int
name|syntacticPredLevel
init|=
literal|0
decl_stmt|;
comment|// Are we generating ASTs (for parsers and tree parsers) right now?
DECL|field|genAST
specifier|protected
name|boolean
name|genAST
init|=
literal|false
decl_stmt|;
comment|// Are we saving the text consumed (for lexers) right now?
DECL|field|saveText
specifier|protected
name|boolean
name|saveText
init|=
literal|false
decl_stmt|;
comment|// Grammar parameters set up to handle different grammar classes.
comment|// These are used to get instanceof tests out of code generation
DECL|field|usingCustomAST
name|boolean
name|usingCustomAST
init|=
literal|false
decl_stmt|;
DECL|field|labeledElementType
name|String
name|labeledElementType
decl_stmt|;
DECL|field|labeledElementASTType
name|String
name|labeledElementASTType
decl_stmt|;
DECL|field|labeledElementInit
name|String
name|labeledElementInit
decl_stmt|;
DECL|field|commonExtraArgs
name|String
name|commonExtraArgs
decl_stmt|;
DECL|field|commonExtraParams
name|String
name|commonExtraParams
decl_stmt|;
DECL|field|commonLocalVars
name|String
name|commonLocalVars
decl_stmt|;
DECL|field|lt1Value
name|String
name|lt1Value
decl_stmt|;
DECL|field|exceptionThrown
name|String
name|exceptionThrown
decl_stmt|;
DECL|field|throwNoViable
name|String
name|throwNoViable
decl_stmt|;
comment|// Tracks the rule being generated.  Used for mapTreeId
DECL|field|currentRule
name|RuleBlock
name|currentRule
decl_stmt|;
comment|// Tracks the rule or labeled subrule being generated.  Used for AST generation.
DECL|field|currentASTResult
name|String
name|currentASTResult
decl_stmt|;
comment|/** Mapping between the ids used in the current alt, and the      * names of variables used to represent their AST values.      */
DECL|field|treeVariableMap
name|Hashtable
name|treeVariableMap
init|=
operator|new
name|Hashtable
argument_list|()
decl_stmt|;
comment|/** Used to keep track of which AST variables have been defined in a rule      * (except for the #rule_name and #rule_name_in var's      */
DECL|field|declaredASTVariables
name|Hashtable
name|declaredASTVariables
init|=
operator|new
name|Hashtable
argument_list|()
decl_stmt|;
comment|/* Count of unnamed generated variables */
DECL|field|astVarNumber
name|int
name|astVarNumber
init|=
literal|1
decl_stmt|;
comment|/** Special value used to mark duplicate in treeVariableMap */
DECL|field|NONUNIQUE
specifier|protected
specifier|static
specifier|final
name|String
name|NONUNIQUE
init|=
operator|new
name|String
argument_list|()
decl_stmt|;
DECL|field|caseSizeThreshold
specifier|public
specifier|static
specifier|final
name|int
name|caseSizeThreshold
init|=
literal|127
decl_stmt|;
comment|// ascii is max
DECL|field|semPreds
specifier|private
name|Vector
name|semPreds
decl_stmt|;
comment|// Used to keep track of which (heterogeneous AST types are used)
comment|// which need to be set in the ASTFactory of the generated parser
DECL|field|astTypes
specifier|private
name|java
operator|.
name|util
operator|.
name|Vector
name|astTypes
decl_stmt|;
DECL|field|nameSpace
specifier|private
specifier|static
name|CSharpNameSpace
name|nameSpace
init|=
literal|null
decl_stmt|;
comment|// _saveIndex creation optimization -- don't create it unless we need to use it
DECL|field|bSaveIndexCreated
name|boolean
name|bSaveIndexCreated
init|=
literal|false
decl_stmt|;
comment|/** Create a CSharp code-generator using the given Grammar.      * The caller must still call setTool, setBehavior, and setAnalyzer      * before generating code.      */
DECL|method|CSharpCodeGenerator ()
specifier|public
name|CSharpCodeGenerator
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
name|charFormatter
operator|=
operator|new
name|CSharpCharFormatter
argument_list|()
expr_stmt|;
block|}
comment|/** Adds a semantic predicate string to the sem pred vector 	    These strings will be used to build an array of sem pred names 	    when building a debugging parser.  This method should only be 	    called when the debug option is specified 	 */
DECL|method|addSemPred (String predicate)
specifier|protected
name|int
name|addSemPred
parameter_list|(
name|String
name|predicate
parameter_list|)
block|{
name|semPreds
operator|.
name|appendElement
argument_list|(
name|predicate
argument_list|)
expr_stmt|;
return|return
name|semPreds
operator|.
name|size
argument_list|()
operator|-
literal|1
return|;
block|}
DECL|method|exitIfError ()
specifier|public
name|void
name|exitIfError
parameter_list|()
block|{
if|if
condition|(
name|antlrTool
operator|.
name|hasError
argument_list|()
condition|)
block|{
name|antlrTool
operator|.
name|fatalError
argument_list|(
literal|"Exiting due to errors."
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**Generate the parser, lexer, treeparser, and token types in CSharp */
DECL|method|gen ()
specifier|public
name|void
name|gen
parameter_list|()
block|{
comment|// Do the code generation
try|try
block|{
comment|// Loop over all grammars
name|Enumeration
name|grammarIter
init|=
name|behavior
operator|.
name|grammars
operator|.
name|elements
argument_list|()
decl_stmt|;
while|while
condition|(
name|grammarIter
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|Grammar
name|g
init|=
operator|(
name|Grammar
operator|)
name|grammarIter
operator|.
name|nextElement
argument_list|()
decl_stmt|;
comment|// Connect all the components to each other
name|g
operator|.
name|setGrammarAnalyzer
argument_list|(
name|analyzer
argument_list|)
expr_stmt|;
name|g
operator|.
name|setCodeGenerator
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|analyzer
operator|.
name|setGrammar
argument_list|(
name|g
argument_list|)
expr_stmt|;
comment|// To get right overloading behavior across heterogeneous grammars
name|setupGrammarParameters
argument_list|(
name|g
argument_list|)
expr_stmt|;
name|g
operator|.
name|generate
argument_list|()
expr_stmt|;
name|exitIfError
argument_list|()
expr_stmt|;
block|}
comment|// Loop over all token managers (some of which are lexers)
name|Enumeration
name|tmIter
init|=
name|behavior
operator|.
name|tokenManagers
operator|.
name|elements
argument_list|()
decl_stmt|;
while|while
condition|(
name|tmIter
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|TokenManager
name|tm
init|=
operator|(
name|TokenManager
operator|)
name|tmIter
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|tm
operator|.
name|isReadOnly
argument_list|()
condition|)
block|{
comment|// Write the token manager tokens as CSharp
comment|// this must appear before genTokenInterchange so that
comment|// labels are set on string literals
name|genTokenTypes
argument_list|(
name|tm
argument_list|)
expr_stmt|;
comment|// Write the token manager tokens as plain text
name|genTokenInterchange
argument_list|(
name|tm
argument_list|)
expr_stmt|;
block|}
name|exitIfError
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|antlrTool
operator|.
name|reportException
argument_list|(
name|e
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The {...} action to generate 	 */
DECL|method|gen (ActionElement action)
specifier|public
name|void
name|gen
parameter_list|(
name|ActionElement
name|action
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genAction("
operator|+
name|action
operator|+
literal|")"
argument_list|)
expr_stmt|;
if|if
condition|(
name|action
operator|.
name|isSemPred
condition|)
block|{
name|genSemPred
argument_list|(
name|action
operator|.
name|actionText
argument_list|,
name|action
operator|.
name|line
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|grammar
operator|.
name|hasSyntacticPredicate
condition|)
block|{
name|println
argument_list|(
literal|"if (0==inputState.guessing)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
name|ActionTransInfo
name|tInfo
init|=
operator|new
name|ActionTransInfo
argument_list|()
decl_stmt|;
name|String
name|actionStr
init|=
name|processActionForSpecialSymbols
argument_list|(
name|action
operator|.
name|actionText
argument_list|,
name|action
operator|.
name|getLine
argument_list|()
argument_list|,
name|currentRule
argument_list|,
name|tInfo
argument_list|)
decl_stmt|;
if|if
condition|(
name|tInfo
operator|.
name|refRuleRoot
operator|!=
literal|null
condition|)
block|{
comment|// Somebody referenced "#rule", make sure translated var is valid
comment|// assignment to #rule is left as a ref also, meaning that assignments
comment|// with no other refs like "#rule = foo();" still forces this code to be
comment|// generated (unnecessarily).
name|println
argument_list|(
name|tInfo
operator|.
name|refRuleRoot
operator|+
literal|" = ("
operator|+
name|labeledElementASTType
operator|+
literal|")currentAST.root;"
argument_list|)
expr_stmt|;
block|}
comment|// dump the translated action
name|printAction
argument_list|(
name|actionStr
argument_list|)
expr_stmt|;
if|if
condition|(
name|tInfo
operator|.
name|assignToRoot
condition|)
block|{
comment|// Somebody did a "#rule=", reset internal currentAST.root
name|println
argument_list|(
literal|"currentAST.root = "
operator|+
name|tInfo
operator|.
name|refRuleRoot
operator|+
literal|";"
argument_list|)
expr_stmt|;
comment|// reset the child pointer too to be last sibling in sibling list
name|println
argument_list|(
literal|"if ( (null != "
operator|+
name|tInfo
operator|.
name|refRuleRoot
operator|+
literal|")&& (null != "
operator|+
name|tInfo
operator|.
name|refRuleRoot
operator|+
literal|".getFirstChild()) )"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"currentAST.child = "
operator|+
name|tInfo
operator|.
name|refRuleRoot
operator|+
literal|".getFirstChild();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"else"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"currentAST.child = "
operator|+
name|tInfo
operator|.
name|refRuleRoot
operator|+
literal|";"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"currentAST.advanceChildToEnd();"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|.
name|hasSyntacticPredicate
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The "x|y|z|..." block to generate 	 */
DECL|method|gen (AlternativeBlock blk)
specifier|public
name|void
name|gen
parameter_list|(
name|AlternativeBlock
name|blk
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"gen("
operator|+
name|blk
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|genBlockPreamble
argument_list|(
name|blk
argument_list|)
expr_stmt|;
name|genBlockInitAction
argument_list|(
name|blk
argument_list|)
expr_stmt|;
comment|// Tell AST generation to build subrule result
name|String
name|saveCurrentASTResult
init|=
name|currentASTResult
decl_stmt|;
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|currentASTResult
operator|=
name|blk
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
name|boolean
name|ok
init|=
name|grammar
operator|.
name|theLLkAnalyzer
operator|.
name|deterministic
argument_list|(
name|blk
argument_list|)
decl_stmt|;
name|CSharpBlockFinishingInfo
name|howToFinish
init|=
name|genCommonBlock
argument_list|(
name|blk
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|genBlockFinish
argument_list|(
name|howToFinish
argument_list|,
name|throwNoViable
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// Restore previous AST generation
name|currentASTResult
operator|=
name|saveCurrentASTResult
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The block-end element to generate.  Block-end 	 * elements are synthesized by the grammar parser to represent 	 * the end of a block. 	 */
DECL|method|gen (BlockEndElement end)
specifier|public
name|void
name|gen
parameter_list|(
name|BlockEndElement
name|end
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genRuleEnd("
operator|+
name|end
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The character literal reference to generate 	 */
DECL|method|gen (CharLiteralElement atom)
specifier|public
name|void
name|gen
parameter_list|(
name|CharLiteralElement
name|atom
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genChar("
operator|+
name|atom
operator|+
literal|")"
argument_list|)
expr_stmt|;
if|if
condition|(
name|atom
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
name|atom
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
name|boolean
name|oldsaveText
init|=
name|saveText
decl_stmt|;
name|saveText
operator|=
name|saveText
operator|&&
name|atom
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
expr_stmt|;
name|genMatch
argument_list|(
name|atom
argument_list|)
expr_stmt|;
name|saveText
operator|=
name|oldsaveText
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The character-range reference to generate 	 */
DECL|method|gen (CharRangeElement r)
specifier|public
name|void
name|gen
parameter_list|(
name|CharRangeElement
name|r
parameter_list|)
block|{
if|if
condition|(
name|r
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|r
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
name|boolean
name|flag
init|=
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
operator|(
name|r
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
operator|)
operator|)
decl_stmt|;
if|if
condition|(
name|flag
condition|)
name|println
argument_list|(
literal|"_saveIndex = text.Length;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"matchRange("
operator|+
name|OctalToUnicode
argument_list|(
name|r
operator|.
name|beginText
argument_list|)
operator|+
literal|","
operator|+
name|OctalToUnicode
argument_list|(
name|r
operator|.
name|endText
argument_list|)
operator|+
literal|");"
argument_list|)
expr_stmt|;
if|if
condition|(
name|flag
condition|)
name|println
argument_list|(
literal|"text.Length = _saveIndex;"
argument_list|)
expr_stmt|;
block|}
comment|/** Generate the lexer CSharp file */
DECL|method|gen (LexerGrammar g)
specifier|public
name|void
name|gen
parameter_list|(
name|LexerGrammar
name|g
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If debugging, create a new sempred vector for this grammar
if|if
condition|(
name|g
operator|.
name|debuggingOutput
condition|)
name|semPreds
operator|=
operator|new
name|Vector
argument_list|()
expr_stmt|;
name|setGrammar
argument_list|(
name|g
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Internal error generating lexer"
argument_list|)
expr_stmt|;
block|}
name|genBody
argument_list|(
name|g
argument_list|)
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The (...)+ block to generate 	 */
DECL|method|gen (OneOrMoreBlock blk)
specifier|public
name|void
name|gen
parameter_list|(
name|OneOrMoreBlock
name|blk
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"gen+("
operator|+
name|blk
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|String
name|label
decl_stmt|;
name|String
name|cnt
decl_stmt|;
name|println
argument_list|(
literal|"{ // ( ... )+"
argument_list|)
expr_stmt|;
name|genBlockPreamble
argument_list|(
name|blk
argument_list|)
expr_stmt|;
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|cnt
operator|=
literal|"_cnt_"
operator|+
name|blk
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|cnt
operator|=
literal|"_cnt"
operator|+
name|blk
operator|.
name|ID
expr_stmt|;
block|}
name|println
argument_list|(
literal|"int "
operator|+
name|cnt
operator|+
literal|"=0;"
argument_list|)
expr_stmt|;
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|label
operator|=
name|blk
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|label
operator|=
literal|"_loop"
operator|+
name|blk
operator|.
name|ID
expr_stmt|;
block|}
name|println
argument_list|(
literal|"for (;;)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// generate the init action for ()+ ()* inside the loop
comment|// this allows us to do usefull EOF checking...
name|genBlockInitAction
argument_list|(
name|blk
argument_list|)
expr_stmt|;
comment|// Tell AST generation to build subrule result
name|String
name|saveCurrentASTResult
init|=
name|currentASTResult
decl_stmt|;
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|currentASTResult
operator|=
name|blk
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
name|boolean
name|ok
init|=
name|grammar
operator|.
name|theLLkAnalyzer
operator|.
name|deterministic
argument_list|(
name|blk
argument_list|)
decl_stmt|;
comment|// generate exit test if greedy set to false
comment|// and an alt is ambiguous with exit branch
comment|// or when lookahead derived purely from end-of-file
comment|// Lookahead analysis stops when end-of-file is hit,
comment|// returning set {epsilon}.  Since {epsilon} is not
comment|// ambig with any real tokens, no error is reported
comment|// by deterministic() routines and we have to check
comment|// for the case where the lookahead depth didn't get
comment|// set to NONDETERMINISTIC (this only happens when the
comment|// FOLLOW contains real atoms + epsilon).
name|boolean
name|generateNonGreedyExitPath
init|=
literal|false
decl_stmt|;
name|int
name|nonGreedyExitDepth
init|=
name|grammar
operator|.
name|maxk
decl_stmt|;
if|if
condition|(
operator|!
name|blk
operator|.
name|greedy
operator|&&
name|blk
operator|.
name|exitLookaheadDepth
operator|<=
name|grammar
operator|.
name|maxk
operator|&&
name|blk
operator|.
name|exitCache
index|[
name|blk
operator|.
name|exitLookaheadDepth
index|]
operator|.
name|containsEpsilon
argument_list|()
condition|)
block|{
name|generateNonGreedyExitPath
operator|=
literal|true
expr_stmt|;
name|nonGreedyExitDepth
operator|=
name|blk
operator|.
name|exitLookaheadDepth
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|blk
operator|.
name|greedy
operator|&&
name|blk
operator|.
name|exitLookaheadDepth
operator|==
name|LLkGrammarAnalyzer
operator|.
name|NONDETERMINISTIC
condition|)
block|{
name|generateNonGreedyExitPath
operator|=
literal|true
expr_stmt|;
block|}
comment|// generate exit test if greedy set to false
comment|// and an alt is ambiguous with exit branch
if|if
condition|(
name|generateNonGreedyExitPath
condition|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"nongreedy (...)+ loop; exit depth is "
operator|+
name|blk
operator|.
name|exitLookaheadDepth
argument_list|)
expr_stmt|;
block|}
name|String
name|predictExit
init|=
name|getLookaheadTestExpression
argument_list|(
name|blk
operator|.
name|exitCache
argument_list|,
name|nonGreedyExitDepth
argument_list|)
decl_stmt|;
name|println
argument_list|(
literal|"// nongreedy exit test"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"if (("
operator|+
name|cnt
operator|+
literal|">= 1)&& "
operator|+
name|predictExit
operator|+
literal|") goto "
operator|+
name|label
operator|+
literal|"_breakloop;"
argument_list|)
expr_stmt|;
block|}
name|CSharpBlockFinishingInfo
name|howToFinish
init|=
name|genCommonBlock
argument_list|(
name|blk
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|genBlockFinish
argument_list|(
name|howToFinish
argument_list|,
literal|"if ("
operator|+
name|cnt
operator|+
literal|">= 1) { goto "
operator|+
name|label
operator|+
literal|"_breakloop; } else { "
operator|+
name|throwNoViable
operator|+
literal|"; }"
argument_list|)
expr_stmt|;
name|println
argument_list|(
name|cnt
operator|+
literal|"++;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|_print
argument_list|(
name|label
operator|+
literal|"_breakloop:"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|";"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}    // ( ... )+"
argument_list|)
expr_stmt|;
comment|// Restore previous AST generation
name|currentASTResult
operator|=
name|saveCurrentASTResult
expr_stmt|;
block|}
comment|/** Generate the parser CSharp file */
DECL|method|gen (ParserGrammar g)
specifier|public
name|void
name|gen
parameter_list|(
name|ParserGrammar
name|g
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if debugging, set up a new vector to keep track of sempred
comment|//   strings for this grammar
if|if
condition|(
name|g
operator|.
name|debuggingOutput
condition|)
name|semPreds
operator|=
operator|new
name|Vector
argument_list|()
expr_stmt|;
name|setGrammar
argument_list|(
name|g
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Internal error generating parser"
argument_list|)
expr_stmt|;
block|}
name|genBody
argument_list|(
name|g
argument_list|)
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The rule-reference to generate 	 */
DECL|method|gen (RuleRefElement rr)
specifier|public
name|void
name|gen
parameter_list|(
name|RuleRefElement
name|rr
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genRR("
operator|+
name|rr
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|grammar
operator|.
name|getSymbol
argument_list|(
name|rr
operator|.
name|targetRule
argument_list|)
decl_stmt|;
if|if
condition|(
name|rs
operator|==
literal|null
operator|||
operator|!
name|rs
operator|.
name|isDefined
argument_list|()
condition|)
block|{
comment|// Is this redundant???
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Rule '"
operator|+
name|rr
operator|.
name|targetRule
operator|+
literal|"' is not defined"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
operator|!
operator|(
name|rs
operator|instanceof
name|RuleSymbol
operator|)
condition|)
block|{
comment|// Is this redundant???
name|antlrTool
operator|.
name|error
argument_list|(
literal|"'"
operator|+
name|rr
operator|.
name|targetRule
operator|+
literal|"' does not name a grammar rule"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
name|genErrorTryForElement
argument_list|(
name|rr
argument_list|)
expr_stmt|;
comment|// AST value for labeled rule refs in tree walker.
comment|// This is not AST construction;  it is just the input tree node value.
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
operator|&&
name|rr
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|rr
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = _t==ASTNULL ? null : "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// if in lexer and ! on rule ref or alt or rule, save buffer index to kill later
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
name|rr
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
condition|)
block|{
name|declareSaveIndexVariableIfNeeded
argument_list|()
expr_stmt|;
name|println
argument_list|(
literal|"_saveIndex = text.Length;"
argument_list|)
expr_stmt|;
block|}
comment|// Process return value assignment if any
name|printTabs
argument_list|()
expr_stmt|;
if|if
condition|(
name|rr
operator|.
name|idAssign
operator|!=
literal|null
condition|)
block|{
comment|// Warn if the rule has no return type
if|if
condition|(
name|rs
operator|.
name|block
operator|.
name|returnAction
operator|==
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Rule '"
operator|+
name|rr
operator|.
name|targetRule
operator|+
literal|"' has no return type"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|_print
argument_list|(
name|rr
operator|.
name|idAssign
operator|+
literal|"="
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Warn about return value if any, but not inside syntactic predicate
if|if
condition|(
operator|!
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
operator|&&
name|syntacticPredLevel
operator|==
literal|0
operator|&&
name|rs
operator|.
name|block
operator|.
name|returnAction
operator|!=
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Rule '"
operator|+
name|rr
operator|.
name|targetRule
operator|+
literal|"' returns a value"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Call the rule
name|GenRuleInvocation
argument_list|(
name|rr
argument_list|)
expr_stmt|;
comment|// if in lexer and ! on element or alt or rule, save buffer index to kill later
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
name|rr
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
condition|)
block|{
name|declareSaveIndexVariableIfNeeded
argument_list|()
expr_stmt|;
name|println
argument_list|(
literal|"text.Length = _saveIndex;"
argument_list|)
expr_stmt|;
block|}
comment|// if not in a syntactic predicate
if|if
condition|(
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|boolean
name|doNoGuessTest
init|=
operator|(
name|grammar
operator|.
name|hasSyntacticPredicate
operator|&&
operator|(
name|grammar
operator|.
name|buildAST
operator|&&
name|rr
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|||
operator|(
name|genAST
operator|&&
name|rr
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
operator|)
operator|)
operator|)
decl_stmt|;
if|if
condition|(
name|doNoGuessTest
condition|)
block|{
name|println
argument_list|(
literal|"if (0 == inputState.guessing)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|.
name|buildAST
operator|&&
name|rr
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// always gen variable for rule return on labeled rules
name|println
argument_list|(
name|rr
operator|.
name|getLabel
argument_list|()
operator|+
literal|"_AST = ("
operator|+
name|labeledElementASTType
operator|+
literal|")returnAST;"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|genAST
condition|)
block|{
switch|switch
condition|(
name|rr
operator|.
name|getAutoGenType
argument_list|()
condition|)
block|{
case|case
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
case|:
if|if
condition|(
name|usingCustomAST
condition|)
name|println
argument_list|(
literal|"astFactory.addASTChild(currentAST, (AST)returnAST);"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|"astFactory.addASTChild(currentAST, returnAST);"
argument_list|)
expr_stmt|;
break|break;
case|case
name|GrammarElement
operator|.
name|AUTO_GEN_CARET
case|:
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Internal: encountered ^ after rule reference"
argument_list|)
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
comment|// if a lexer and labeled, Token label defined at rule level, just set it here
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
name|rr
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
name|rr
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = returnToken_;"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|doNoGuessTest
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
name|genErrorCatchForElement
argument_list|(
name|rr
argument_list|)
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The string-literal reference to generate 	 */
DECL|method|gen (StringLiteralElement atom)
specifier|public
name|void
name|gen
parameter_list|(
name|StringLiteralElement
name|atom
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genString("
operator|+
name|atom
operator|+
literal|")"
argument_list|)
expr_stmt|;
comment|// Variable declarations for labeled elements
if|if
condition|(
name|atom
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|atom
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// AST
name|genElementAST
argument_list|(
name|atom
argument_list|)
expr_stmt|;
comment|// is there a bang on the literal?
name|boolean
name|oldsaveText
init|=
name|saveText
decl_stmt|;
name|saveText
operator|=
name|saveText
operator|&&
name|atom
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
expr_stmt|;
comment|// matching
name|genMatch
argument_list|(
name|atom
argument_list|)
expr_stmt|;
name|saveText
operator|=
name|oldsaveText
expr_stmt|;
comment|// tack on tree cursor motion if doing a tree walker
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"_t = _t.getNextSibling();"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The token-range reference to generate 	 */
DECL|method|gen (TokenRangeElement r)
specifier|public
name|void
name|gen
parameter_list|(
name|TokenRangeElement
name|r
parameter_list|)
block|{
name|genErrorTryForElement
argument_list|(
name|r
argument_list|)
expr_stmt|;
if|if
condition|(
name|r
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|r
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// AST
name|genElementAST
argument_list|(
name|r
argument_list|)
expr_stmt|;
comment|// match
name|println
argument_list|(
literal|"matchRange("
operator|+
name|OctalToUnicode
argument_list|(
name|r
operator|.
name|beginText
argument_list|)
operator|+
literal|","
operator|+
name|OctalToUnicode
argument_list|(
name|r
operator|.
name|endText
argument_list|)
operator|+
literal|");"
argument_list|)
expr_stmt|;
name|genErrorCatchForElement
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The token-reference to generate 	 */
DECL|method|gen (TokenRefElement atom)
specifier|public
name|void
name|gen
parameter_list|(
name|TokenRefElement
name|atom
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genTokenRef("
operator|+
name|atom
operator|+
literal|")"
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Token reference found in lexer"
argument_list|)
expr_stmt|;
block|}
name|genErrorTryForElement
argument_list|(
name|atom
argument_list|)
expr_stmt|;
comment|// Assign Token value to token label variable
if|if
condition|(
name|atom
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|atom
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// AST
name|genElementAST
argument_list|(
name|atom
argument_list|)
expr_stmt|;
comment|// matching
name|genMatch
argument_list|(
name|atom
argument_list|)
expr_stmt|;
name|genErrorCatchForElement
argument_list|(
name|atom
argument_list|)
expr_stmt|;
comment|// tack on tree cursor motion if doing a tree walker
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"_t = _t.getNextSibling();"
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|gen (TreeElement t)
specifier|public
name|void
name|gen
parameter_list|(
name|TreeElement
name|t
parameter_list|)
block|{
comment|// save AST cursor
name|println
argument_list|(
literal|"AST __t"
operator|+
name|t
operator|.
name|ID
operator|+
literal|" = _t;"
argument_list|)
expr_stmt|;
comment|// If there is a label on the root, then assign that to the variable
if|if
condition|(
name|t
operator|.
name|root
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
name|t
operator|.
name|root
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = (ASTNULL == _t) ? null : ("
operator|+
name|labeledElementASTType
operator|+
literal|")_t;"
argument_list|)
expr_stmt|;
block|}
comment|// check for invalid modifiers ! and ^ on tree element roots
if|if
condition|(
name|t
operator|.
name|root
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
condition|)
block|{
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Suffixing a root node with '!' is not implemented"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|t
operator|.
name|getLine
argument_list|()
argument_list|,
name|t
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
name|t
operator|.
name|root
operator|.
name|setAutoGenType
argument_list|(
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|t
operator|.
name|root
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_CARET
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Suffixing a root node with '^' is redundant; already a root"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|t
operator|.
name|getLine
argument_list|()
argument_list|,
name|t
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
name|t
operator|.
name|root
operator|.
name|setAutoGenType
argument_list|(
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
argument_list|)
expr_stmt|;
block|}
comment|// Generate AST variables
name|genElementAST
argument_list|(
name|t
operator|.
name|root
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
comment|// Save the AST construction state
name|println
argument_list|(
literal|"ASTPair __currentAST"
operator|+
name|t
operator|.
name|ID
operator|+
literal|" = currentAST.copy();"
argument_list|)
expr_stmt|;
comment|// Make the next item added a child of the TreeElement root
name|println
argument_list|(
literal|"currentAST.root = currentAST.child;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"currentAST.child = null;"
argument_list|)
expr_stmt|;
block|}
comment|// match root
if|if
condition|(
name|t
operator|.
name|root
operator|instanceof
name|WildcardElement
condition|)
block|{
name|println
argument_list|(
literal|"if (null == _t) throw new MismatchedTokenException();"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|genMatch
argument_list|(
name|t
operator|.
name|root
argument_list|)
expr_stmt|;
block|}
comment|// move to list of children
name|println
argument_list|(
literal|"_t = _t.getFirstChild();"
argument_list|)
expr_stmt|;
comment|// walk list of children, generating code for each
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|t
operator|.
name|getAlternatives
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Alternative
name|a
init|=
name|t
operator|.
name|getAlternativeAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|AlternativeElement
name|e
init|=
name|a
operator|.
name|head
decl_stmt|;
while|while
condition|(
name|e
operator|!=
literal|null
condition|)
block|{
name|e
operator|.
name|generate
argument_list|()
expr_stmt|;
name|e
operator|=
name|e
operator|.
name|next
expr_stmt|;
block|}
block|}
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
comment|// restore the AST construction state to that just after the
comment|// tree root was added
name|println
argument_list|(
literal|"currentAST = __currentAST"
operator|+
name|t
operator|.
name|ID
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// restore AST cursor
name|println
argument_list|(
literal|"_t = __t"
operator|+
name|t
operator|.
name|ID
operator|+
literal|";"
argument_list|)
expr_stmt|;
comment|// move cursor to sibling of tree just parsed
name|println
argument_list|(
literal|"_t = _t.getNextSibling();"
argument_list|)
expr_stmt|;
block|}
comment|/** Generate the tree-parser CSharp file */
DECL|method|gen (TreeWalkerGrammar g)
specifier|public
name|void
name|gen
parameter_list|(
name|TreeWalkerGrammar
name|g
parameter_list|)
throws|throws
name|IOException
block|{
comment|// SAS: debugging stuff removed for now...
name|setGrammar
argument_list|(
name|g
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
operator|)
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Internal error generating tree-walker"
argument_list|)
expr_stmt|;
block|}
name|genBody
argument_list|(
name|g
argument_list|)
expr_stmt|;
block|}
comment|/** Generate code for the given grammar element. 	 * @param wc The wildcard element to generate 	 */
DECL|method|gen (WildcardElement wc)
specifier|public
name|void
name|gen
parameter_list|(
name|WildcardElement
name|wc
parameter_list|)
block|{
comment|// Variable assignment for labeled elements
if|if
condition|(
name|wc
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|wc
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// AST
name|genElementAST
argument_list|(
name|wc
argument_list|)
expr_stmt|;
comment|// Match anything but EOF
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"if (null == _t) throw new MismatchedTokenException();"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
name|wc
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
condition|)
block|{
name|declareSaveIndexVariableIfNeeded
argument_list|()
expr_stmt|;
name|println
argument_list|(
literal|"_saveIndex = text.Length;"
argument_list|)
expr_stmt|;
block|}
name|println
argument_list|(
literal|"matchNot(EOF/*_CHAR*/);"
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
name|wc
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
condition|)
block|{
name|declareSaveIndexVariableIfNeeded
argument_list|()
expr_stmt|;
name|println
argument_list|(
literal|"text.Length = _saveIndex;"
argument_list|)
expr_stmt|;
comment|// kill text atom put in buffer
block|}
block|}
else|else
block|{
name|println
argument_list|(
literal|"matchNot("
operator|+
name|getValueString
argument_list|(
name|Token
operator|.
name|EOF_TYPE
argument_list|)
operator|+
literal|");"
argument_list|)
expr_stmt|;
block|}
comment|// tack on tree cursor motion if doing a tree walker
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"_t = _t.getNextSibling();"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Generate code for the given grammar element. 	 * @param blk The (...)* block to generate 	 */
DECL|method|gen (ZeroOrMoreBlock blk)
specifier|public
name|void
name|gen
parameter_list|(
name|ZeroOrMoreBlock
name|blk
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"gen*("
operator|+
name|blk
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{    // ( ... )*"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|genBlockPreamble
argument_list|(
name|blk
argument_list|)
expr_stmt|;
name|String
name|label
decl_stmt|;
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|label
operator|=
name|blk
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|label
operator|=
literal|"_loop"
operator|+
name|blk
operator|.
name|ID
expr_stmt|;
block|}
name|println
argument_list|(
literal|"for (;;)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// generate the init action for ()+ ()* inside the loop
comment|// this allows us to do usefull EOF checking...
name|genBlockInitAction
argument_list|(
name|blk
argument_list|)
expr_stmt|;
comment|// Tell AST generation to build subrule result
name|String
name|saveCurrentASTResult
init|=
name|currentASTResult
decl_stmt|;
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|currentASTResult
operator|=
name|blk
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
name|boolean
name|ok
init|=
name|grammar
operator|.
name|theLLkAnalyzer
operator|.
name|deterministic
argument_list|(
name|blk
argument_list|)
decl_stmt|;
comment|// generate exit test if greedy set to false
comment|// and an alt is ambiguous with exit branch
comment|// or when lookahead derived purely from end-of-file
comment|// Lookahead analysis stops when end-of-file is hit,
comment|// returning set {epsilon}.  Since {epsilon} is not
comment|// ambig with any real tokens, no error is reported
comment|// by deterministic() routines and we have to check
comment|// for the case where the lookahead depth didn't get
comment|// set to NONDETERMINISTIC (this only happens when the
comment|// FOLLOW contains real atoms + epsilon).
name|boolean
name|generateNonGreedyExitPath
init|=
literal|false
decl_stmt|;
name|int
name|nonGreedyExitDepth
init|=
name|grammar
operator|.
name|maxk
decl_stmt|;
if|if
condition|(
operator|!
name|blk
operator|.
name|greedy
operator|&&
name|blk
operator|.
name|exitLookaheadDepth
operator|<=
name|grammar
operator|.
name|maxk
operator|&&
name|blk
operator|.
name|exitCache
index|[
name|blk
operator|.
name|exitLookaheadDepth
index|]
operator|.
name|containsEpsilon
argument_list|()
condition|)
block|{
name|generateNonGreedyExitPath
operator|=
literal|true
expr_stmt|;
name|nonGreedyExitDepth
operator|=
name|blk
operator|.
name|exitLookaheadDepth
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|blk
operator|.
name|greedy
operator|&&
name|blk
operator|.
name|exitLookaheadDepth
operator|==
name|LLkGrammarAnalyzer
operator|.
name|NONDETERMINISTIC
condition|)
block|{
name|generateNonGreedyExitPath
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|generateNonGreedyExitPath
condition|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"nongreedy (...)* loop; exit depth is "
operator|+
name|blk
operator|.
name|exitLookaheadDepth
argument_list|)
expr_stmt|;
block|}
name|String
name|predictExit
init|=
name|getLookaheadTestExpression
argument_list|(
name|blk
operator|.
name|exitCache
argument_list|,
name|nonGreedyExitDepth
argument_list|)
decl_stmt|;
name|println
argument_list|(
literal|"// nongreedy exit test"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"if ("
operator|+
name|predictExit
operator|+
literal|") goto "
operator|+
name|label
operator|+
literal|"_breakloop;"
argument_list|)
expr_stmt|;
block|}
name|CSharpBlockFinishingInfo
name|howToFinish
init|=
name|genCommonBlock
argument_list|(
name|blk
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|genBlockFinish
argument_list|(
name|howToFinish
argument_list|,
literal|"goto "
operator|+
name|label
operator|+
literal|"_breakloop;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|_print
argument_list|(
name|label
operator|+
literal|"_breakloop:"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|";"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}    // ( ... )*"
argument_list|)
expr_stmt|;
comment|// Restore previous AST generation
name|currentASTResult
operator|=
name|saveCurrentASTResult
expr_stmt|;
block|}
comment|/** Generate an alternative. 	  * @param alt  The alternative to generate 	  * @param blk The block to which the alternative belongs 	  */
DECL|method|genAlt (Alternative alt, AlternativeBlock blk)
specifier|protected
name|void
name|genAlt
parameter_list|(
name|Alternative
name|alt
parameter_list|,
name|AlternativeBlock
name|blk
parameter_list|)
block|{
comment|// Save the AST generation state, and set it to that of the alt
name|boolean
name|savegenAST
init|=
name|genAST
decl_stmt|;
name|genAST
operator|=
name|genAST
operator|&&
name|alt
operator|.
name|getAutoGen
argument_list|()
expr_stmt|;
name|boolean
name|oldsaveTest
init|=
name|saveText
decl_stmt|;
name|saveText
operator|=
name|saveText
operator|&&
name|alt
operator|.
name|getAutoGen
argument_list|()
expr_stmt|;
comment|// Reset the variable name map for the alternative
name|Hashtable
name|saveMap
init|=
name|treeVariableMap
decl_stmt|;
name|treeVariableMap
operator|=
operator|new
name|Hashtable
argument_list|()
expr_stmt|;
comment|// Generate try block around the alt for  error handling
if|if
condition|(
name|alt
operator|.
name|exceptionSpec
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"try        // for error handling"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
name|AlternativeElement
name|elem
init|=
name|alt
operator|.
name|head
decl_stmt|;
while|while
condition|(
operator|!
operator|(
name|elem
operator|instanceof
name|BlockEndElement
operator|)
condition|)
block|{
name|elem
operator|.
name|generate
argument_list|()
expr_stmt|;
comment|// alt can begin with anything. Ask target to gen.
name|elem
operator|=
name|elem
operator|.
name|next
expr_stmt|;
block|}
if|if
condition|(
name|genAST
condition|)
block|{
if|if
condition|(
name|blk
operator|instanceof
name|RuleBlock
condition|)
block|{
comment|// Set the AST return value for the rule
name|RuleBlock
name|rblk
init|=
operator|(
name|RuleBlock
operator|)
name|blk
decl_stmt|;
if|if
condition|(
name|usingCustomAST
condition|)
block|{
name|println
argument_list|(
name|rblk
operator|.
name|getRuleName
argument_list|()
operator|+
literal|"_AST = ("
operator|+
name|labeledElementASTType
operator|+
literal|")currentAST.root;"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
name|rblk
operator|.
name|getRuleName
argument_list|()
operator|+
literal|"_AST = currentAST.root;"
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// ### future: also set AST value for labeled subrules.
comment|// println(blk.getLabel() + "_AST = ("+labeledElementASTType+")currentAST.root;");
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Labeled subrules not yet supported"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|blk
operator|.
name|getLine
argument_list|()
argument_list|,
name|blk
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|alt
operator|.
name|exceptionSpec
operator|!=
literal|null
condition|)
block|{
comment|// close try block
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|genErrorHandler
argument_list|(
name|alt
operator|.
name|exceptionSpec
argument_list|)
expr_stmt|;
block|}
name|genAST
operator|=
name|savegenAST
expr_stmt|;
name|saveText
operator|=
name|oldsaveTest
expr_stmt|;
name|treeVariableMap
operator|=
name|saveMap
expr_stmt|;
block|}
comment|/** Generate all the bitsets to be used in the parser or lexer 	 * Generate the raw bitset data like "long _tokenSet1_data[] = {...};" 	 * and the BitSet object declarations like "BitSet _tokenSet1 = new BitSet(_tokenSet1_data);" 	 * Note that most languages do not support object initialization inside a 	 * class definition, so other code-generators may have to separate the 	 * bitset declarations from the initializations (e.g., put the initializations 	 * in the generated constructor instead). 	 * @param bitsetList The list of bitsets to generate. 	 * @param maxVocabulary Ensure that each generated bitset can contain at least this value. 	 */
DECL|method|genBitsets ( Vector bitsetList, int maxVocabulary )
specifier|protected
name|void
name|genBitsets
parameter_list|(
name|Vector
name|bitsetList
parameter_list|,
name|int
name|maxVocabulary
parameter_list|)
block|{
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bitsetList
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|BitSet
name|p
init|=
operator|(
name|BitSet
operator|)
name|bitsetList
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// Ensure that generated BitSet is large enough for vocabulary
name|p
operator|.
name|growToInclude
argument_list|(
name|maxVocabulary
argument_list|)
expr_stmt|;
name|genBitSet
argument_list|(
name|p
argument_list|,
name|i
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Do something simple like:      *  private static final long[] mk_tokenSet_0() {      *    long[] data = { -2305839160922996736L, 63L, 16777216L, 0L, 0L, 0L };      *    return data;      *  }      *  public static final BitSet _tokenSet_0 = new BitSet(mk_tokenSet_0());      *      *  Or, for large bitsets, optimize init so ranges are collapsed into loops.      *  This is most useful for lexers using unicode.      */
DECL|method|genBitSet (BitSet p, int id)
specifier|private
name|void
name|genBitSet
parameter_list|(
name|BitSet
name|p
parameter_list|,
name|int
name|id
parameter_list|)
block|{
comment|// initialization data
name|println
argument_list|(
literal|"private static long[] mk_"
operator|+
name|getBitsetName
argument_list|(
name|id
argument_list|)
operator|+
literal|"()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|int
name|n
init|=
name|p
operator|.
name|lengthInLongWords
argument_list|()
decl_stmt|;
if|if
condition|(
name|n
operator|<
name|BITSET_OPTIMIZE_INIT_THRESHOLD
condition|)
block|{
name|println
argument_list|(
literal|"long[] data = { "
operator|+
name|p
operator|.
name|toStringOfWords
argument_list|()
operator|+
literal|"};"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// will init manually, allocate space then set values
name|println
argument_list|(
literal|"long[] data = new long["
operator|+
name|n
operator|+
literal|"];"
argument_list|)
expr_stmt|;
name|long
index|[]
name|elems
init|=
name|p
operator|.
name|toPackedArray
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|elems
operator|.
name|length
condition|;
control|)
block|{
if|if
condition|(
operator|(
name|i
operator|+
literal|1
operator|)
operator|==
name|elems
operator|.
name|length
operator|||
name|elems
index|[
name|i
index|]
operator|!=
name|elems
index|[
name|i
operator|+
literal|1
index|]
condition|)
block|{
comment|// last number or no run of numbers, just dump assignment
name|println
argument_list|(
literal|"data["
operator|+
name|i
operator|+
literal|"]="
operator|+
name|elems
index|[
name|i
index|]
operator|+
literal|"L;"
argument_list|)
expr_stmt|;
name|i
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|// scan to find end of run
name|int
name|j
decl_stmt|;
for|for
control|(
name|j
operator|=
name|i
operator|+
literal|1
init|;
name|j
operator|<
name|elems
operator|.
name|length
operator|&&
name|elems
index|[
name|j
index|]
operator|==
name|elems
index|[
name|i
index|]
condition|;
name|j
operator|++
control|)
block|{
empty_stmt|;
block|}
comment|// j-1 is last member of run
name|println
argument_list|(
literal|"for (int i = "
operator|+
name|i
operator|+
literal|"; i<="
operator|+
operator|(
name|j
operator|-
literal|1
operator|)
operator|+
literal|"; i++) { data[i]="
operator|+
name|elems
index|[
name|i
index|]
operator|+
literal|"L; }"
argument_list|)
expr_stmt|;
name|i
operator|=
name|j
expr_stmt|;
block|}
block|}
block|}
name|println
argument_list|(
literal|"return data;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// BitSet object
name|println
argument_list|(
literal|"public static readonly BitSet "
operator|+
name|getBitsetName
argument_list|(
name|id
argument_list|)
operator|+
literal|" = new BitSet("
operator|+
literal|"mk_"
operator|+
name|getBitsetName
argument_list|(
name|id
argument_list|)
operator|+
literal|"()"
operator|+
literal|");"
argument_list|)
expr_stmt|;
block|}
comment|/** Given the index of a bitset in the bitset list, generate a unique name.      * Specific code-generators may want to override this      * if the language does not allow '_' or numerals in identifiers.      * @param index  The index of the bitset in the bitset list.      */
DECL|method|getBitsetName (int index)
specifier|protected
name|String
name|getBitsetName
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
literal|"tokenSet_"
operator|+
name|index
operator|+
literal|"_"
return|;
block|}
comment|/** Generate the finish of a block, using a combination of the info 	* returned from genCommonBlock() and the action to perform when 	* no alts were taken 	* @param howToFinish The return of genCommonBlock() 	* @param noViableAction What to generate when no alt is taken 	*/
DECL|method|genBlockFinish (CSharpBlockFinishingInfo howToFinish, String noViableAction)
specifier|private
name|void
name|genBlockFinish
parameter_list|(
name|CSharpBlockFinishingInfo
name|howToFinish
parameter_list|,
name|String
name|noViableAction
parameter_list|)
block|{
if|if
condition|(
name|howToFinish
operator|.
name|needAnErrorClause
operator|&&
operator|(
name|howToFinish
operator|.
name|generatedAnIf
operator|||
name|howToFinish
operator|.
name|generatedSwitch
operator|)
condition|)
block|{
if|if
condition|(
name|howToFinish
operator|.
name|generatedAnIf
condition|)
block|{
name|println
argument_list|(
literal|"else"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
name|noViableAction
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|howToFinish
operator|.
name|postscript
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|howToFinish
operator|.
name|needAnErrorClause
operator|&&
name|howToFinish
operator|.
name|generatedSwitch
operator|&&
operator|!
name|howToFinish
operator|.
name|generatedAnIf
operator|&&
name|noViableAction
operator|!=
literal|null
condition|)
block|{
comment|// Check to make sure that noViableAction is only a throw statement
if|if
condition|(
name|noViableAction
operator|.
name|indexOf
argument_list|(
literal|"throw"
argument_list|)
operator|==
literal|0
operator|||
name|noViableAction
operator|.
name|indexOf
argument_list|(
literal|"goto"
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|// Remove the break statement since it isn't reachable with a throw exception
name|int
name|endOfBreak
init|=
name|howToFinish
operator|.
name|postscript
operator|.
name|indexOf
argument_list|(
literal|"break;"
argument_list|)
operator|+
literal|6
decl_stmt|;
name|String
name|newPostScript
init|=
name|howToFinish
operator|.
name|postscript
operator|.
name|substring
argument_list|(
name|endOfBreak
argument_list|)
decl_stmt|;
name|println
argument_list|(
name|newPostScript
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
name|howToFinish
operator|.
name|postscript
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|println
argument_list|(
name|howToFinish
operator|.
name|postscript
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/** Generate the init action for a block, which may be a RuleBlock or a      * plain AlternativeBLock.      * @blk The block for which the preamble is to be generated.      */
DECL|method|genBlockInitAction (AlternativeBlock blk)
specifier|protected
name|void
name|genBlockInitAction
parameter_list|(
name|AlternativeBlock
name|blk
parameter_list|)
block|{
comment|// dump out init action
if|if
condition|(
name|blk
operator|.
name|initAction
operator|!=
literal|null
condition|)
block|{
name|printAction
argument_list|(
name|processActionForSpecialSymbols
argument_list|(
name|blk
operator|.
name|initAction
argument_list|,
name|blk
operator|.
name|getLine
argument_list|()
argument_list|,
name|currentRule
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Generate the header for a block, which may be a RuleBlock or a      * plain AlternativeBLock.  This generates any variable declarations      * and syntactic-predicate-testing variables. 	 * @blk The block for which the preamble is to be generated. 	 */
DECL|method|genBlockPreamble (AlternativeBlock blk)
specifier|protected
name|void
name|genBlockPreamble
parameter_list|(
name|AlternativeBlock
name|blk
parameter_list|)
block|{
comment|// define labels for rule blocks.
if|if
condition|(
name|blk
operator|instanceof
name|RuleBlock
condition|)
block|{
name|RuleBlock
name|rblk
init|=
operator|(
name|RuleBlock
operator|)
name|blk
decl_stmt|;
if|if
condition|(
name|rblk
operator|.
name|labeledElements
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rblk
operator|.
name|labeledElements
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|AlternativeElement
name|a
init|=
operator|(
name|AlternativeElement
operator|)
name|rblk
operator|.
name|labeledElements
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|//System.out.println("looking at labeled element: "+a);
comment|//Variables for labeled rule refs and
comment|//subrules are different than variables for
comment|//grammar atoms.  This test is a little tricky
comment|//because we want to get all rule refs and ebnf,
comment|//but not rule blocks or syntactic predicates
if|if
condition|(
name|a
operator|instanceof
name|RuleRefElement
operator|||
name|a
operator|instanceof
name|AlternativeBlock
operator|&&
operator|!
operator|(
name|a
operator|instanceof
name|RuleBlock
operator|)
operator|&&
operator|!
operator|(
name|a
operator|instanceof
name|SynPredBlock
operator|)
condition|)
block|{
if|if
condition|(
operator|!
operator|(
name|a
operator|instanceof
name|RuleRefElement
operator|)
operator|&&
operator|(
operator|(
name|AlternativeBlock
operator|)
name|a
operator|)
operator|.
name|not
operator|&&
name|analyzer
operator|.
name|subruleCanBeInverted
argument_list|(
operator|(
operator|(
name|AlternativeBlock
operator|)
name|a
operator|)
argument_list|,
name|grammar
operator|instanceof
name|LexerGrammar
argument_list|)
condition|)
block|{
comment|// Special case for inverted subrules that
comment|// will be inlined.  Treat these like
comment|// token or char literal references
name|println
argument_list|(
name|labeledElementType
operator|+
literal|" "
operator|+
name|a
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|labeledElementInit
operator|+
literal|";"
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
name|genASTDeclaration
argument_list|(
name|a
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
comment|// Always gen AST variables for
comment|// labeled elements, even if the
comment|// element itself is marked with !
name|genASTDeclaration
argument_list|(
name|a
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"Token "
operator|+
name|a
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = null;"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
comment|// always generate rule-ref variables
comment|// for tree walker
name|println
argument_list|(
name|labeledElementType
operator|+
literal|" "
operator|+
name|a
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|labeledElementInit
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// It is a token or literal reference.  Generate the
comment|// correct variable type for this grammar
name|println
argument_list|(
name|labeledElementType
operator|+
literal|" "
operator|+
name|a
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|labeledElementInit
operator|+
literal|";"
argument_list|)
expr_stmt|;
comment|// In addition, generate *_AST variables if building ASTs
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
comment|//println(labeledElementASTType+" " + a.getLabel() + "_AST = null;");
if|if
condition|(
name|a
operator|instanceof
name|GrammarAtom
operator|&&
operator|(
operator|(
name|GrammarAtom
operator|)
name|a
operator|)
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|GrammarAtom
name|ga
init|=
operator|(
name|GrammarAtom
operator|)
name|a
decl_stmt|;
name|genASTDeclaration
argument_list|(
name|a
argument_list|,
name|ga
operator|.
name|getASTNodeType
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|genASTDeclaration
argument_list|(
name|a
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
block|}
DECL|method|genBody (LexerGrammar g)
specifier|public
name|void
name|genBody
parameter_list|(
name|LexerGrammar
name|g
parameter_list|)
throws|throws
name|IOException
block|{
comment|// SAS: moved output creation to method so a subclass can change
comment|//      how the output is generated (for VAJ interface)
name|setupOutput
argument_list|(
name|grammar
operator|.
name|getClassName
argument_list|()
argument_list|)
expr_stmt|;
name|genAST
operator|=
literal|false
expr_stmt|;
comment|// no way to gen trees.
name|saveText
operator|=
literal|true
expr_stmt|;
comment|// save consumed characters.
name|tabs
operator|=
literal|0
expr_stmt|;
comment|// Generate header common to all CSharp output files
name|genHeader
argument_list|()
expr_stmt|;
comment|// Do not use printAction because we assume tabs==0
name|println
argument_list|(
name|behavior
operator|.
name|getHeaderAction
argument_list|(
literal|""
argument_list|)
argument_list|)
expr_stmt|;
comment|// Generate the CSharp namespace declaration (if specified)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitDeclarations
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate header specific to lexer CSharp file
comment|// println("import java.io.FileInputStream;");
name|println
argument_list|(
literal|"// Generate header specific to lexer CSharp file"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using System;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using Stream                          = System.IO.Stream;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TextReader                      = System.IO.TextReader;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using Hashtable                       = System.Collections.Hashtable;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using Comparer                        = System.Collections.Comparer;"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|g
operator|.
name|caseSensitiveLiterals
operator|)
condition|)
block|{
name|println
argument_list|(
literal|"using CaseInsensitiveHashCodeProvider = System.Collections.CaseInsensitiveHashCodeProvider;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using CaseInsensitiveComparer         = System.Collections.CaseInsensitiveComparer;"
argument_list|)
expr_stmt|;
block|}
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStreamException            = antlr.TokenStreamException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStreamIOException          = antlr.TokenStreamIOException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStreamRecognitionException = antlr.TokenStreamRecognitionException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using CharStreamException             = antlr.CharStreamException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using CharStreamIOException           = antlr.CharStreamIOException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ANTLRException                  = antlr.ANTLRException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using CharScanner                     = antlr.CharScanner;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using InputBuffer                     = antlr.InputBuffer;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ByteBuffer                      = antlr.ByteBuffer;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using CharBuffer                      = antlr.CharBuffer;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using Token                           = antlr.Token;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using CommonToken                     = antlr.CommonToken;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using SemanticException               = antlr.SemanticException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using RecognitionException            = antlr.RecognitionException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using NoViableAltForCharException     = antlr.NoViableAltForCharException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using MismatchedCharException         = antlr.MismatchedCharException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStream                     = antlr.TokenStream;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using LexerSharedInputState           = antlr.LexerSharedInputState;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using BitSet                          = antlr.collections.impl.BitSet;"
argument_list|)
expr_stmt|;
comment|// Generate user-defined lexer file preamble
name|println
argument_list|(
name|grammar
operator|.
name|preambleAction
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
comment|// Generate lexer class definition
name|String
name|sup
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|grammar
operator|.
name|superClass
operator|!=
literal|null
condition|)
block|{
name|sup
operator|=
name|grammar
operator|.
name|superClass
expr_stmt|;
block|}
else|else
block|{
name|sup
operator|=
literal|"antlr."
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
expr_stmt|;
block|}
comment|// print javadoc comment if any
if|if
condition|(
name|grammar
operator|.
name|comment
operator|!=
literal|null
condition|)
block|{
name|_println
argument_list|(
name|grammar
operator|.
name|comment
argument_list|)
expr_stmt|;
block|}
name|Token
name|tprefix
init|=
operator|(
name|Token
operator|)
name|grammar
operator|.
name|options
operator|.
name|get
argument_list|(
literal|"classHeaderPrefix"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tprefix
operator|==
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"public "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|p
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tprefix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"public "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|print
argument_list|(
name|p
operator|+
literal|" "
argument_list|)
expr_stmt|;
block|}
block|}
name|print
argument_list|(
literal|"class "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|" : "
operator|+
name|sup
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|", TokenStream"
argument_list|)
expr_stmt|;
name|Token
name|tsuffix
init|=
operator|(
name|Token
operator|)
name|grammar
operator|.
name|options
operator|.
name|get
argument_list|(
literal|"classHeaderSuffix"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tsuffix
operator|!=
literal|null
condition|)
block|{
name|String
name|suffix
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tsuffix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|!=
literal|null
condition|)
block|{
name|print
argument_list|(
literal|", "
operator|+
name|suffix
argument_list|)
expr_stmt|;
comment|// must be an interface name for CSharp
block|}
block|}
name|println
argument_list|(
literal|" {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate 'const' definitions for Token IDs
name|genTokenDefinitions
argument_list|(
name|grammar
operator|.
name|tokenManager
argument_list|)
expr_stmt|;
comment|// Generate user-defined lexer class members
name|print
argument_list|(
name|processActionForSpecialSymbols
argument_list|(
name|grammar
operator|.
name|classMemberAction
operator|.
name|getText
argument_list|()
argument_list|,
name|grammar
operator|.
name|classMemberAction
operator|.
name|getLine
argument_list|()
argument_list|,
name|currentRule
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
comment|//
comment|// Generate the constructor from InputStream, which in turn
comment|// calls the ByteBuffer constructor
comment|//
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(Stream ins) : this(new ByteBuffer(ins))"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|//
comment|// Generate the constructor from Reader, which in turn
comment|// calls the CharBuffer constructor
comment|//
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(TextReader r) : this(new CharBuffer(r))"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|print
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(InputBuffer ib)"
argument_list|)
expr_stmt|;
comment|// if debugging, wrap the input buffer in a debugger
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
name|println
argument_list|(
literal|" : this(new LexerSharedInputState(new antlr.debug.DebuggingInputBuffer(ib)))"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|" : this(new LexerSharedInputState(ib))"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|//
comment|// Generate the constructor from InputBuffer (char or byte)
comment|//
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(LexerSharedInputState state) : base(state)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"initialize();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// Generate the initialize function
name|println
argument_list|(
literal|"private void initialize()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// if debugging, set up array variables and call user-overridable
comment|//   debugging setup method
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
block|{
name|println
argument_list|(
literal|"ruleNames  = _ruleNames;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"semPredNames = _semPredNames;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"setupDebugging();"
argument_list|)
expr_stmt|;
block|}
comment|// Generate the setting of various generated options.
comment|// These need to be before the literals since ANTLRHashString depends on
comment|// the casesensitive stuff.
name|println
argument_list|(
literal|"caseSensitiveLiterals = "
operator|+
name|g
operator|.
name|caseSensitiveLiterals
operator|+
literal|";"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"setCaseSensitive("
operator|+
name|g
operator|.
name|caseSensitive
operator|+
literal|");"
argument_list|)
expr_stmt|;
comment|// Generate the initialization of a hashtable
comment|// containing the string literals used in the lexer
comment|// The literals variable itself is in CharScanner
if|if
condition|(
name|g
operator|.
name|caseSensitiveLiterals
condition|)
name|println
argument_list|(
literal|"literals = new Hashtable(100, (float) 0.4, null, Comparer.Default);"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|"literals = new Hashtable(100, (float) 0.4, CaseInsensitiveHashCodeProvider.Default, CaseInsensitiveComparer.Default);"
argument_list|)
expr_stmt|;
name|Enumeration
name|keys
init|=
name|grammar
operator|.
name|tokenManager
operator|.
name|getTokenSymbolKeys
argument_list|()
decl_stmt|;
while|while
condition|(
name|keys
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|String
name|key
init|=
operator|(
name|String
operator|)
name|keys
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
name|key
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
operator|!=
literal|'"'
condition|)
block|{
continue|continue;
block|}
name|TokenSymbol
name|sym
init|=
name|grammar
operator|.
name|tokenManager
operator|.
name|getTokenSymbol
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|sym
operator|instanceof
name|StringLiteralSymbol
condition|)
block|{
name|StringLiteralSymbol
name|s
init|=
operator|(
name|StringLiteralSymbol
operator|)
name|sym
decl_stmt|;
name|println
argument_list|(
literal|"literals.Add("
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|", "
operator|+
name|s
operator|.
name|getTokenType
argument_list|()
operator|+
literal|");"
argument_list|)
expr_stmt|;
block|}
block|}
name|Enumeration
name|ids
decl_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// generate the rule name array for debugging
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
block|{
name|println
argument_list|(
literal|"private const string[] _ruleNames = {"
argument_list|)
expr_stmt|;
name|ids
operator|=
name|grammar
operator|.
name|rules
operator|.
name|elements
argument_list|()
expr_stmt|;
name|int
name|ruleNum
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|ids
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|GrammarSymbol
name|sym
init|=
operator|(
name|GrammarSymbol
operator|)
name|ids
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
name|sym
operator|instanceof
name|RuleSymbol
condition|)
name|println
argument_list|(
literal|"  \""
operator|+
operator|(
operator|(
name|RuleSymbol
operator|)
name|sym
operator|)
operator|.
name|getId
argument_list|()
operator|+
literal|"\","
argument_list|)
expr_stmt|;
block|}
name|println
argument_list|(
literal|"};"
argument_list|)
expr_stmt|;
block|}
comment|// Generate nextToken() rule.
comment|// nextToken() is a synthetic lexer rule that is the implicit OR of all
comment|// user-defined lexer rules.
name|genNextToken
argument_list|()
expr_stmt|;
comment|// Generate code for each rule in the lexer
name|ids
operator|=
name|grammar
operator|.
name|rules
operator|.
name|elements
argument_list|()
expr_stmt|;
name|int
name|ruleNum
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|ids
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|RuleSymbol
name|sym
init|=
operator|(
name|RuleSymbol
operator|)
name|ids
operator|.
name|nextElement
argument_list|()
decl_stmt|;
comment|// Don't generate the synthetic rules
if|if
condition|(
operator|!
name|sym
operator|.
name|getId
argument_list|()
operator|.
name|equals
argument_list|(
literal|"mnextToken"
argument_list|)
condition|)
block|{
name|genRule
argument_list|(
name|sym
argument_list|,
literal|false
argument_list|,
name|ruleNum
operator|++
argument_list|,
name|grammar
operator|.
name|tokenManager
argument_list|)
expr_stmt|;
block|}
name|exitIfError
argument_list|()
expr_stmt|;
block|}
comment|// Generate the semantic predicate map for debugging
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
name|genSemPredMap
argument_list|()
expr_stmt|;
comment|// Generate the bitsets used throughout the lexer
name|genBitsets
argument_list|(
name|bitsetsUsed
argument_list|,
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|charVocabulary
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
comment|// Generate the CSharp namespace closures (if required)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitClosures
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
comment|// Close the lexer output stream
name|currentOutput
operator|.
name|close
argument_list|()
expr_stmt|;
name|currentOutput
operator|=
literal|null
expr_stmt|;
block|}
DECL|method|genInitFactory ( Grammar g )
specifier|public
name|void
name|genInitFactory
parameter_list|(
name|Grammar
name|g
parameter_list|)
block|{
if|if
condition|(
name|g
operator|.
name|buildAST
condition|)
block|{
comment|// Generate the method to initialize an ASTFactory when we're
comment|// building AST's
name|println
argument_list|(
literal|"static public void initializeASTFactory( ASTFactory factory )"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"factory.setMaxNodeType("
operator|+
name|g
operator|.
name|tokenManager
operator|.
name|maxTokenType
argument_list|()
operator|+
literal|");"
argument_list|)
expr_stmt|;
comment|// Walk the token vocabulary and generate code to register every TokenID->ASTNodeType
comment|// mapping specified in the  tokens {...} section with the ASTFactory.
name|Vector
name|v
init|=
name|g
operator|.
name|tokenManager
operator|.
name|getVocabulary
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|v
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|s
init|=
operator|(
name|String
operator|)
name|v
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
name|TokenSymbol
name|ts
init|=
name|g
operator|.
name|tokenManager
operator|.
name|getTokenSymbol
argument_list|(
name|s
argument_list|)
decl_stmt|;
if|if
condition|(
name|ts
operator|!=
literal|null
operator|&&
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"factory.setTokenTypeASTNodeType("
operator|+
name|s
operator|+
literal|", \""
operator|+
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|+
literal|"\");"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|genBody (ParserGrammar g)
specifier|public
name|void
name|genBody
parameter_list|(
name|ParserGrammar
name|g
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Open the output stream for the parser and set the currentOutput
comment|// SAS: moved file setup so subclass could do it (for VAJ interface)
name|setupOutput
argument_list|(
name|grammar
operator|.
name|getClassName
argument_list|()
argument_list|)
expr_stmt|;
name|genAST
operator|=
name|grammar
operator|.
name|buildAST
expr_stmt|;
name|tabs
operator|=
literal|0
expr_stmt|;
comment|// Generate the header common to all output files.
name|genHeader
argument_list|()
expr_stmt|;
comment|// Do not use printAction because we assume tabs==0
name|println
argument_list|(
name|behavior
operator|.
name|getHeaderAction
argument_list|(
literal|""
argument_list|)
argument_list|)
expr_stmt|;
comment|// Generate the CSharp namespace declaration (if specified)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitDeclarations
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate header for the parser
name|println
argument_list|(
literal|"// Generate the header common to all output files."
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using System;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenBuffer              = antlr.TokenBuffer;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStreamException     = antlr.TokenStreamException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStreamIOException   = antlr.TokenStreamIOException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ANTLRException           = antlr.ANTLRException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using "
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
operator|+
literal|" = antlr."
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
operator|+
literal|";"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using Token                    = antlr.Token;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using TokenStream              = antlr.TokenStream;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using RecognitionException     = antlr.RecognitionException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using NoViableAltException     = antlr.NoViableAltException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using MismatchedTokenException = antlr.MismatchedTokenException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using SemanticException        = antlr.SemanticException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ParserSharedInputState   = antlr.ParserSharedInputState;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using BitSet                   = antlr.collections.impl.BitSet;"
argument_list|)
expr_stmt|;
if|if
condition|(
name|genAST
condition|)
block|{
name|println
argument_list|(
literal|"using AST                      = antlr.collections.AST;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ASTPair                  = antlr.ASTPair;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ASTFactory               = antlr.ASTFactory;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ASTArray                 = antlr.collections.impl.ASTArray;"
argument_list|)
expr_stmt|;
block|}
comment|// Output the user-defined parser preamble
name|println
argument_list|(
name|grammar
operator|.
name|preambleAction
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
comment|// Generate parser class definition
name|String
name|sup
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|grammar
operator|.
name|superClass
operator|!=
literal|null
condition|)
name|sup
operator|=
name|grammar
operator|.
name|superClass
expr_stmt|;
else|else
name|sup
operator|=
literal|"antlr."
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
expr_stmt|;
comment|// print javadoc comment if any
if|if
condition|(
name|grammar
operator|.
name|comment
operator|!=
literal|null
condition|)
block|{
name|_println
argument_list|(
name|grammar
operator|.
name|comment
argument_list|)
expr_stmt|;
block|}
name|Token
name|tprefix
init|=
operator|(
name|Token
operator|)
name|grammar
operator|.
name|options
operator|.
name|get
argument_list|(
literal|"classHeaderPrefix"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tprefix
operator|==
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"public "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|p
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tprefix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"public "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|print
argument_list|(
name|p
operator|+
literal|" "
argument_list|)
expr_stmt|;
block|}
block|}
name|println
argument_list|(
literal|"class "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|" : "
operator|+
name|sup
argument_list|)
expr_stmt|;
name|Token
name|tsuffix
init|=
operator|(
name|Token
operator|)
name|grammar
operator|.
name|options
operator|.
name|get
argument_list|(
literal|"classHeaderSuffix"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tsuffix
operator|!=
literal|null
condition|)
block|{
name|String
name|suffix
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tsuffix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|!=
literal|null
condition|)
name|print
argument_list|(
literal|"              , "
operator|+
name|suffix
argument_list|)
expr_stmt|;
comment|// must be an interface name for CSharp
block|}
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate 'const' definitions for Token IDs
name|genTokenDefinitions
argument_list|(
name|grammar
operator|.
name|tokenManager
argument_list|)
expr_stmt|;
comment|// set up an array of all the rule names so the debugger can
comment|// keep track of them only by number -- less to store in tree...
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
block|{
name|println
argument_list|(
literal|"private const string[] _ruleNames = {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|Enumeration
name|ids
init|=
name|grammar
operator|.
name|rules
operator|.
name|elements
argument_list|()
decl_stmt|;
name|int
name|ruleNum
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|ids
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|GrammarSymbol
name|sym
init|=
operator|(
name|GrammarSymbol
operator|)
name|ids
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
name|sym
operator|instanceof
name|RuleSymbol
condition|)
name|println
argument_list|(
literal|"  \""
operator|+
operator|(
operator|(
name|RuleSymbol
operator|)
name|sym
operator|)
operator|.
name|getId
argument_list|()
operator|+
literal|"\","
argument_list|)
expr_stmt|;
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"};"
argument_list|)
expr_stmt|;
block|}
comment|// Generate user-defined parser class members
name|print
argument_list|(
name|processActionForSpecialSymbols
argument_list|(
name|grammar
operator|.
name|classMemberAction
operator|.
name|getText
argument_list|()
argument_list|,
name|grammar
operator|.
name|classMemberAction
operator|.
name|getLine
argument_list|()
argument_list|,
name|currentRule
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
comment|// Generate parser class constructor from TokenBuffer
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"protected void initialize()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"tokenNames = tokenNames_;"
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
name|println
argument_list|(
literal|"initializeFactory();"
argument_list|)
expr_stmt|;
comment|// if debugging, set up arrays and call the user-overridable
comment|//   debugging setup method
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
block|{
name|println
argument_list|(
literal|"ruleNames  = _ruleNames;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"semPredNames = _semPredNames;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"setupDebugging(tokenBuf);"
argument_list|)
expr_stmt|;
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"protected "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(TokenBuffer tokenBuf, int k) : base(tokenBuf, k)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"initialize();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(TokenBuffer tokenBuf) : this(tokenBuf,"
operator|+
name|grammar
operator|.
name|maxk
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|// Generate parser class constructor from TokenStream
name|println
argument_list|(
literal|"protected "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(TokenStream lexer, int k) : base(lexer,k)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"initialize();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(TokenStream lexer) : this(lexer,"
operator|+
name|grammar
operator|.
name|maxk
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"(ParserSharedInputState state) : base(state,"
operator|+
name|grammar
operator|.
name|maxk
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"initialize();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|astTypes
operator|=
operator|new
name|java
operator|.
name|util
operator|.
name|Vector
argument_list|(
literal|100
argument_list|)
expr_stmt|;
comment|// Generate code for each rule in the grammar
name|Enumeration
name|ids
init|=
name|grammar
operator|.
name|rules
operator|.
name|elements
argument_list|()
decl_stmt|;
name|int
name|ruleNum
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|ids
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|GrammarSymbol
name|sym
init|=
operator|(
name|GrammarSymbol
operator|)
name|ids
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
name|sym
operator|instanceof
name|RuleSymbol
condition|)
block|{
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|sym
decl_stmt|;
name|genRule
argument_list|(
name|rs
argument_list|,
name|rs
operator|.
name|references
operator|.
name|size
argument_list|()
operator|==
literal|0
argument_list|,
name|ruleNum
operator|++
argument_list|,
name|grammar
operator|.
name|tokenManager
argument_list|)
expr_stmt|;
block|}
name|exitIfError
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|usingCustomAST
condition|)
block|{
comment|// when we are using a custom AST, overload Parser.getAST() to return the
comment|// custom AST type
name|println
argument_list|(
literal|"public new "
operator|+
name|labeledElementASTType
operator|+
literal|" getAST()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"return ("
operator|+
name|labeledElementASTType
operator|+
literal|") returnAST;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|// Generate the method that initializes the ASTFactory when we're
comment|// building AST's
name|println
argument_list|(
literal|"private void initializeFactory()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
name|println
argument_list|(
literal|"if (astFactory == null)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
if|if
condition|(
name|usingCustomAST
condition|)
block|{
name|println
argument_list|(
literal|"astFactory = new ASTFactory(\""
operator|+
name|labeledElementASTType
operator|+
literal|"\");"
argument_list|)
expr_stmt|;
block|}
else|else
name|println
argument_list|(
literal|"astFactory = new ASTFactory();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"initializeASTFactory( astFactory );"
argument_list|)
expr_stmt|;
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|genInitFactory
argument_list|(
name|g
argument_list|)
expr_stmt|;
comment|// Generate the token names
name|genTokenStrings
argument_list|()
expr_stmt|;
comment|// Generate the bitsets used throughout the grammar
name|genBitsets
argument_list|(
name|bitsetsUsed
argument_list|,
name|grammar
operator|.
name|tokenManager
operator|.
name|maxTokenType
argument_list|()
argument_list|)
expr_stmt|;
comment|// Generate the semantic predicate map for debugging
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
name|genSemPredMap
argument_list|()
expr_stmt|;
comment|// Close class definition
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
comment|// Generate the CSharp namespace closures (if required)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitClosures
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
comment|// Close the parser output stream
name|currentOutput
operator|.
name|close
argument_list|()
expr_stmt|;
name|currentOutput
operator|=
literal|null
expr_stmt|;
block|}
DECL|method|genBody (TreeWalkerGrammar g)
specifier|public
name|void
name|genBody
parameter_list|(
name|TreeWalkerGrammar
name|g
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Open the output stream for the parser and set the currentOutput
comment|// SAS: move file open to method so subclass can override it
comment|//      (mainly for VAJ interface)
name|setupOutput
argument_list|(
name|grammar
operator|.
name|getClassName
argument_list|()
argument_list|)
expr_stmt|;
name|genAST
operator|=
name|grammar
operator|.
name|buildAST
expr_stmt|;
name|tabs
operator|=
literal|0
expr_stmt|;
comment|// Generate the header common to all output files.
name|genHeader
argument_list|()
expr_stmt|;
comment|// Do not use printAction because we assume tabs==0
name|println
argument_list|(
name|behavior
operator|.
name|getHeaderAction
argument_list|(
literal|""
argument_list|)
argument_list|)
expr_stmt|;
comment|// Generate the CSharp namespace declaration (if specified)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitDeclarations
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate header specific to the tree-parser CSharp file
name|println
argument_list|(
literal|"// Generate header specific to the tree-parser CSharp file"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using System;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using "
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
operator|+
literal|" = antlr."
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
operator|+
literal|";"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using Token                    = antlr.Token;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using AST                      = antlr.collections.AST;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using RecognitionException     = antlr.RecognitionException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ANTLRException           = antlr.ANTLRException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using NoViableAltException     = antlr.NoViableAltException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using MismatchedTokenException = antlr.MismatchedTokenException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using SemanticException        = antlr.SemanticException;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using BitSet                   = antlr.collections.impl.BitSet;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ASTPair                  = antlr.ASTPair;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ASTFactory               = antlr.ASTFactory;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"using ASTArray                 = antlr.collections.impl.ASTArray;"
argument_list|)
expr_stmt|;
comment|// Output the user-defined parser premamble
name|println
argument_list|(
name|grammar
operator|.
name|preambleAction
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
comment|// Generate parser class definition
name|String
name|sup
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|grammar
operator|.
name|superClass
operator|!=
literal|null
condition|)
block|{
name|sup
operator|=
name|grammar
operator|.
name|superClass
expr_stmt|;
block|}
else|else
block|{
name|sup
operator|=
literal|"antlr."
operator|+
name|grammar
operator|.
name|getSuperClass
argument_list|()
expr_stmt|;
block|}
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|// print javadoc comment if any
if|if
condition|(
name|grammar
operator|.
name|comment
operator|!=
literal|null
condition|)
block|{
name|_println
argument_list|(
name|grammar
operator|.
name|comment
argument_list|)
expr_stmt|;
block|}
name|Token
name|tprefix
init|=
operator|(
name|Token
operator|)
name|grammar
operator|.
name|options
operator|.
name|get
argument_list|(
literal|"classHeaderPrefix"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tprefix
operator|==
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"public "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|p
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tprefix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"public "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|print
argument_list|(
name|p
operator|+
literal|" "
argument_list|)
expr_stmt|;
block|}
block|}
name|println
argument_list|(
literal|"class "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|" : "
operator|+
name|sup
argument_list|)
expr_stmt|;
name|Token
name|tsuffix
init|=
operator|(
name|Token
operator|)
name|grammar
operator|.
name|options
operator|.
name|get
argument_list|(
literal|"classHeaderSuffix"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tsuffix
operator|!=
literal|null
condition|)
block|{
name|String
name|suffix
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tsuffix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|!=
literal|null
condition|)
block|{
name|print
argument_list|(
literal|"              , "
operator|+
name|suffix
argument_list|)
expr_stmt|;
comment|// must be an interface name for CSharp
block|}
block|}
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate 'const' definitions for Token IDs
name|genTokenDefinitions
argument_list|(
name|grammar
operator|.
name|tokenManager
argument_list|)
expr_stmt|;
comment|// Generate user-defined parser class members
name|print
argument_list|(
name|processActionForSpecialSymbols
argument_list|(
name|grammar
operator|.
name|classMemberAction
operator|.
name|getText
argument_list|()
argument_list|,
name|grammar
operator|.
name|classMemberAction
operator|.
name|getLine
argument_list|()
argument_list|,
name|currentRule
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
comment|// Generate default parser class constructor
name|println
argument_list|(
literal|"public "
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|"()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"tokenNames = tokenNames_;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|astTypes
operator|=
operator|new
name|java
operator|.
name|util
operator|.
name|Vector
argument_list|()
expr_stmt|;
comment|// Generate code for each rule in the grammar
name|Enumeration
name|ids
init|=
name|grammar
operator|.
name|rules
operator|.
name|elements
argument_list|()
decl_stmt|;
name|int
name|ruleNum
init|=
literal|0
decl_stmt|;
name|String
name|ruleNameInits
init|=
literal|""
decl_stmt|;
while|while
condition|(
name|ids
operator|.
name|hasMoreElements
argument_list|()
condition|)
block|{
name|GrammarSymbol
name|sym
init|=
operator|(
name|GrammarSymbol
operator|)
name|ids
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
name|sym
operator|instanceof
name|RuleSymbol
condition|)
block|{
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|sym
decl_stmt|;
name|genRule
argument_list|(
name|rs
argument_list|,
name|rs
operator|.
name|references
operator|.
name|size
argument_list|()
operator|==
literal|0
argument_list|,
name|ruleNum
operator|++
argument_list|,
name|grammar
operator|.
name|tokenManager
argument_list|)
expr_stmt|;
block|}
name|exitIfError
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|usingCustomAST
condition|)
block|{
comment|// when we are using a custom ast override Parser.getAST to return the
comment|// custom AST type
name|println
argument_list|(
literal|"public new "
operator|+
name|labeledElementASTType
operator|+
literal|" getAST()"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"return ("
operator|+
name|labeledElementASTType
operator|+
literal|") returnAST;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|// Generate the ASTFactory initialization function
name|genInitFactory
argument_list|(
name|grammar
argument_list|)
expr_stmt|;
comment|// Generate the token names
name|genTokenStrings
argument_list|()
expr_stmt|;
comment|// Generate the bitsets used throughout the grammar
name|genBitsets
argument_list|(
name|bitsetsUsed
argument_list|,
name|grammar
operator|.
name|tokenManager
operator|.
name|maxTokenType
argument_list|()
argument_list|)
expr_stmt|;
comment|// Close class definition
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
comment|// Generate the CSharp namespace closures (if required)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitClosures
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
comment|// Close the parser output stream
name|currentOutput
operator|.
name|close
argument_list|()
expr_stmt|;
name|currentOutput
operator|=
literal|null
expr_stmt|;
block|}
comment|/** Generate a series of case statements that implement a BitSet test. 	 * @param p The Bitset for which cases are to be generated 	 */
DECL|method|genCases (BitSet p)
specifier|protected
name|void
name|genCases
parameter_list|(
name|BitSet
name|p
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genCases("
operator|+
name|p
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|int
index|[]
name|elems
decl_stmt|;
name|elems
operator|=
name|p
operator|.
name|toArray
argument_list|()
expr_stmt|;
comment|// Wrap cases four-per-line for lexer, one-per-line for parser
name|int
name|wrap
init|=
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
condition|?
literal|4
else|:
literal|1
decl_stmt|;
name|int
name|j
init|=
literal|1
decl_stmt|;
name|boolean
name|startOfLine
init|=
literal|true
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|elems
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|j
operator|==
literal|1
condition|)
block|{
name|print
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|_print
argument_list|(
literal|"  "
argument_list|)
expr_stmt|;
block|}
name|_print
argument_list|(
literal|"case "
operator|+
name|getValueString
argument_list|(
name|elems
index|[
name|i
index|]
argument_list|)
operator|+
literal|":"
argument_list|)
expr_stmt|;
if|if
condition|(
name|j
operator|==
name|wrap
condition|)
block|{
name|_println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|startOfLine
operator|=
literal|true
expr_stmt|;
name|j
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
name|j
operator|++
expr_stmt|;
name|startOfLine
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|startOfLine
condition|)
block|{
name|_println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**Generate common code for a block of alternatives; return a 	* postscript that needs to be generated at the end of the 	* block.  Other routines may append else-clauses and such for 	* error checking before the postfix is generated.  If the 	* grammar is a lexer, then generate alternatives in an order 	* where alternatives requiring deeper lookahead are generated 	* first, and EOF in the lookahead set reduces the depth of 	* the lookahead.  @param blk The block to generate @param 	* noTestForSingle If true, then it does not generate a test 	* for a single alternative. 	*/
DECL|method|genCommonBlock (AlternativeBlock blk, boolean noTestForSingle)
specifier|public
name|CSharpBlockFinishingInfo
name|genCommonBlock
parameter_list|(
name|AlternativeBlock
name|blk
parameter_list|,
name|boolean
name|noTestForSingle
parameter_list|)
block|{
name|int
name|nIF
init|=
literal|0
decl_stmt|;
name|boolean
name|createdLL1Switch
init|=
literal|false
decl_stmt|;
name|int
name|closingBracesOfIFSequence
init|=
literal|0
decl_stmt|;
name|CSharpBlockFinishingInfo
name|finishingInfo
init|=
operator|new
name|CSharpBlockFinishingInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genCommonBlock("
operator|+
name|blk
operator|+
literal|")"
argument_list|)
expr_stmt|;
comment|// Save the AST generation state, and set it to that of the block
name|boolean
name|savegenAST
init|=
name|genAST
decl_stmt|;
name|genAST
operator|=
name|genAST
operator|&&
name|blk
operator|.
name|getAutoGen
argument_list|()
expr_stmt|;
name|boolean
name|oldsaveTest
init|=
name|saveText
decl_stmt|;
name|saveText
operator|=
name|saveText
operator|&&
name|blk
operator|.
name|getAutoGen
argument_list|()
expr_stmt|;
comment|// Is this block inverted?  If so, generate special-case code
if|if
condition|(
name|blk
operator|.
name|not
operator|&&
name|analyzer
operator|.
name|subruleCanBeInverted
argument_list|(
name|blk
argument_list|,
name|grammar
operator|instanceof
name|LexerGrammar
argument_list|)
condition|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"special case: ~(subrule)"
argument_list|)
expr_stmt|;
name|Lookahead
name|p
init|=
name|analyzer
operator|.
name|look
argument_list|(
literal|1
argument_list|,
name|blk
argument_list|)
decl_stmt|;
comment|// Variable assignment for labeled elements
if|if
condition|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
name|blk
operator|.
name|getLabel
argument_list|()
operator|+
literal|" = "
operator|+
name|lt1Value
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// AST
name|genElementAST
argument_list|(
name|blk
argument_list|)
expr_stmt|;
name|String
name|astArgs
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
if|if
condition|(
name|usingCustomAST
condition|)
name|astArgs
operator|=
literal|"(AST)_t,"
expr_stmt|;
else|else
name|astArgs
operator|=
literal|"_t,"
expr_stmt|;
block|}
comment|// match the bitset for the alternative
name|println
argument_list|(
literal|"match("
operator|+
name|astArgs
operator|+
name|getBitsetName
argument_list|(
name|markBitsetForGen
argument_list|(
name|p
operator|.
name|fset
argument_list|)
argument_list|)
operator|+
literal|");"
argument_list|)
expr_stmt|;
comment|// tack on tree cursor motion if doing a tree walker
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"_t = _t.getNextSibling();"
argument_list|)
expr_stmt|;
block|}
return|return
name|finishingInfo
return|;
block|}
comment|// Special handling for single alt
if|if
condition|(
name|blk
operator|.
name|getAlternatives
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
name|Alternative
name|alt
init|=
name|blk
operator|.
name|getAlternativeAt
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// Generate a warning if there is a synPred for single alt.
if|if
condition|(
name|alt
operator|.
name|synPred
operator|!=
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Syntactic predicate superfluous for single alternative"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|blk
operator|.
name|getAlternativeAt
argument_list|(
literal|0
argument_list|)
operator|.
name|synPred
operator|.
name|getLine
argument_list|()
argument_list|,
name|blk
operator|.
name|getAlternativeAt
argument_list|(
literal|0
argument_list|)
operator|.
name|synPred
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|noTestForSingle
condition|)
block|{
if|if
condition|(
name|alt
operator|.
name|semPred
operator|!=
literal|null
condition|)
block|{
comment|// Generate validating predicate
name|genSemPred
argument_list|(
name|alt
operator|.
name|semPred
argument_list|,
name|blk
operator|.
name|line
argument_list|)
expr_stmt|;
block|}
name|genAlt
argument_list|(
name|alt
argument_list|,
name|blk
argument_list|)
expr_stmt|;
return|return
name|finishingInfo
return|;
block|}
block|}
comment|// count number of simple LL(1) cases; only do switch for
comment|// many LL(1) cases (no preds, no end of token refs)
comment|// We don't care about exit paths for (...)*, (...)+
comment|// because we don't explicitly have a test for them
comment|// as an alt in the loop.
comment|//
comment|// Also, we now count how many unicode lookahead sets
comment|// there are--they must be moved to DEFAULT or ELSE
comment|// clause.
name|int
name|nLL1
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|blk
operator|.
name|getAlternatives
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Alternative
name|a
init|=
name|blk
operator|.
name|getAlternativeAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|suitableForCaseExpression
argument_list|(
name|a
argument_list|)
condition|)
block|{
name|nLL1
operator|++
expr_stmt|;
block|}
block|}
comment|// do LL(1) cases
if|if
condition|(
name|nLL1
operator|>=
name|makeSwitchThreshold
condition|)
block|{
comment|// Determine the name of the item to be compared
name|String
name|testExpr
init|=
name|lookaheadString
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|createdLL1Switch
operator|=
literal|true
expr_stmt|;
comment|// when parsing trees, convert null to valid tree node with NULL lookahead
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"if (null == _t)"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"_t = ASTNULL;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
block|}
name|println
argument_list|(
literal|"switch ( "
operator|+
name|testExpr
operator|+
literal|" )"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
comment|//tabs++;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|blk
operator|.
name|alternatives
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Alternative
name|alt
init|=
name|blk
operator|.
name|getAlternativeAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// ignore any non-LL(1) alts, predicated alts,
comment|// or end-of-token alts for case expressions
name|bSaveIndexCreated
operator|=
literal|false
expr_stmt|;
if|if
condition|(
operator|!
name|suitableForCaseExpression
argument_list|(
name|alt
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|Lookahead
name|p
init|=
name|alt
operator|.
name|cache
index|[
literal|1
index|]
decl_stmt|;
if|if
condition|(
name|p
operator|.
name|fset
operator|.
name|degree
argument_list|()
operator|==
literal|0
operator|&&
operator|!
name|p
operator|.
name|containsEpsilon
argument_list|()
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Alternate omitted due to empty prediction set"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|alt
operator|.
name|head
operator|.
name|getLine
argument_list|()
argument_list|,
name|alt
operator|.
name|head
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|genCases
argument_list|(
name|p
operator|.
name|fset
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|genAlt
argument_list|(
name|alt
argument_list|,
name|blk
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"break;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
name|println
argument_list|(
literal|"default:"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
comment|// do non-LL(1) and nondeterministic cases This is tricky in
comment|// the lexer, because of cases like: STAR : '*' ; ASSIGN_STAR
comment|// : "*="; Since nextToken is generated without a loop, then
comment|// the STAR will have end-of-token as it's lookahead set for
comment|// LA(2).  So, we must generate the alternatives containing
comment|// trailing end-of-token in their lookahead sets *after* the
comment|// alternatives without end-of-token.  This implements the
comment|// usual lexer convention that longer matches come before
comment|// shorter ones, e.g.  "*=" matches ASSIGN_STAR not STAR
comment|//
comment|// For non-lexer grammars, this does not sort the alternates
comment|// by depth Note that alts whose lookahead is purely
comment|// end-of-token at k=1 end up as default or else clauses.
name|int
name|startDepth
init|=
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
condition|?
name|grammar
operator|.
name|maxk
else|:
literal|0
decl_stmt|;
for|for
control|(
name|int
name|altDepth
init|=
name|startDepth
init|;
name|altDepth
operator|>=
literal|0
condition|;
name|altDepth
operator|--
control|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"checking depth "
operator|+
name|altDepth
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|blk
operator|.
name|alternatives
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Alternative
name|alt
init|=
name|blk
operator|.
name|getAlternativeAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genAlt: "
operator|+
name|i
argument_list|)
expr_stmt|;
comment|// if we made a switch above, ignore what we already took care
comment|// of.  Specifically, LL(1) alts with no preds
comment|// that do not have end-of-token in their prediction set
comment|// and that are not giant unicode sets.
if|if
condition|(
name|createdLL1Switch
operator|&&
name|suitableForCaseExpression
argument_list|(
name|alt
argument_list|)
condition|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"ignoring alt because it was in the switch"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|String
name|e
decl_stmt|;
name|boolean
name|unpredicted
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
comment|// Calculate the "effective depth" of the alt,
comment|// which is the max depth at which
comment|// cache[depth]!=end-of-token
name|int
name|effectiveDepth
init|=
name|alt
operator|.
name|lookaheadDepth
decl_stmt|;
if|if
condition|(
name|effectiveDepth
operator|==
name|GrammarAnalyzer
operator|.
name|NONDETERMINISTIC
condition|)
block|{
comment|// use maximum lookahead
name|effectiveDepth
operator|=
name|grammar
operator|.
name|maxk
expr_stmt|;
block|}
while|while
condition|(
name|effectiveDepth
operator|>=
literal|1
operator|&&
name|alt
operator|.
name|cache
index|[
name|effectiveDepth
index|]
operator|.
name|containsEpsilon
argument_list|()
condition|)
block|{
name|effectiveDepth
operator|--
expr_stmt|;
block|}
comment|// Ignore alts whose effective depth is other than
comment|// the ones we are generating for this iteration.
if|if
condition|(
name|effectiveDepth
operator|!=
name|altDepth
condition|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"ignoring alt because effectiveDepth!=altDepth;"
operator|+
name|effectiveDepth
operator|+
literal|"!="
operator|+
name|altDepth
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|unpredicted
operator|=
name|lookaheadIsEmpty
argument_list|(
name|alt
argument_list|,
name|effectiveDepth
argument_list|)
expr_stmt|;
name|e
operator|=
name|getLookaheadTestExpression
argument_list|(
name|alt
argument_list|,
name|effectiveDepth
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|unpredicted
operator|=
name|lookaheadIsEmpty
argument_list|(
name|alt
argument_list|,
name|grammar
operator|.
name|maxk
argument_list|)
expr_stmt|;
name|e
operator|=
name|getLookaheadTestExpression
argument_list|(
name|alt
argument_list|,
name|grammar
operator|.
name|maxk
argument_list|)
expr_stmt|;
block|}
comment|// Was it a big unicode range that forced unsuitability
comment|// for a case expression?
if|if
condition|(
name|alt
operator|.
name|cache
index|[
literal|1
index|]
operator|.
name|fset
operator|.
name|degree
argument_list|()
operator|>
name|caseSizeThreshold
operator|&&
name|suitableForCaseExpression
argument_list|(
name|alt
argument_list|)
condition|)
block|{
if|if
condition|(
name|nIF
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
literal|"if "
operator|+
name|e
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"else if "
operator|+
name|e
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|unpredicted
operator|&&
name|alt
operator|.
name|semPred
operator|==
literal|null
operator|&&
name|alt
operator|.
name|synPred
operator|==
literal|null
condition|)
block|{
comment|// The alt has empty prediction set and no
comment|// predicate to help out.  if we have not
comment|// generated a previous if, just put {...} around
comment|// the end-of-token clause
if|if
condition|(
name|nIF
operator|==
literal|0
condition|)
block|{
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"else {"
argument_list|)
expr_stmt|;
block|}
name|finishingInfo
operator|.
name|needAnErrorClause
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
comment|// check for sem and syn preds
comment|// Add any semantic predicate expression to the lookahead test
if|if
condition|(
name|alt
operator|.
name|semPred
operator|!=
literal|null
condition|)
block|{
comment|// if debugging, wrap the evaluation of the predicate in a method
comment|//
comment|// translate $ and # references
name|ActionTransInfo
name|tInfo
init|=
operator|new
name|ActionTransInfo
argument_list|()
decl_stmt|;
name|String
name|actionStr
init|=
name|processActionForSpecialSymbols
argument_list|(
name|alt
operator|.
name|semPred
argument_list|,
name|blk
operator|.
name|line
argument_list|,
name|currentRule
argument_list|,
name|tInfo
argument_list|)
decl_stmt|;
comment|// ignore translation info...we don't need to
comment|// do anything with it.  call that will inform
comment|// SemanticPredicateListeners of the result
if|if
condition|(
operator|(
operator|(
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
operator|||
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
operator|)
operator|&&
name|grammar
operator|.
name|debuggingOutput
condition|)
block|{
name|e
operator|=
literal|"("
operator|+
name|e
operator|+
literal|"&& fireSemanticPredicateEvaluated(antlr.debug.SemanticPredicateEvent.PREDICTING,"
operator|+
comment|//FIXME
name|addSemPred
argument_list|(
name|charFormatter
operator|.
name|escapeString
argument_list|(
name|actionStr
argument_list|)
argument_list|)
operator|+
literal|","
operator|+
name|actionStr
operator|+
literal|"))"
expr_stmt|;
block|}
else|else
block|{
name|e
operator|=
literal|"("
operator|+
name|e
operator|+
literal|"&&("
operator|+
name|actionStr
operator|+
literal|"))"
expr_stmt|;
block|}
block|}
comment|// Generate any syntactic predicates
if|if
condition|(
name|nIF
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|alt
operator|.
name|synPred
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"else {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|genSynPred
argument_list|(
name|alt
operator|.
name|synPred
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|closingBracesOfIFSequence
operator|++
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"else if "
operator|+
name|e
operator|+
literal|" {"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|alt
operator|.
name|synPred
operator|!=
literal|null
condition|)
block|{
name|genSynPred
argument_list|(
name|alt
operator|.
name|synPred
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// when parsing trees, convert null to valid tree node
comment|// with NULL lookahead.
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"if (_t == null)"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"_t = ASTNULL;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
block|}
name|println
argument_list|(
literal|"if "
operator|+
name|e
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|nIF
operator|++
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|genAlt
argument_list|(
name|alt
argument_list|,
name|blk
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
name|String
name|ps
init|=
literal|""
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|closingBracesOfIFSequence
condition|;
name|i
operator|++
control|)
block|{
name|ps
operator|+=
literal|"}"
expr_stmt|;
block|}
comment|// Restore the AST generation state
name|genAST
operator|=
name|savegenAST
expr_stmt|;
comment|// restore save text state
name|saveText
operator|=
name|oldsaveTest
expr_stmt|;
comment|// Return the finishing info.
if|if
condition|(
name|createdLL1Switch
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
name|finishingInfo
operator|.
name|postscript
operator|=
name|ps
operator|+
literal|"break; }"
expr_stmt|;
name|finishingInfo
operator|.
name|generatedSwitch
operator|=
literal|true
expr_stmt|;
name|finishingInfo
operator|.
name|generatedAnIf
operator|=
name|nIF
operator|>
literal|0
expr_stmt|;
comment|//return new CSharpBlockFinishingInfo(ps+"}",true,nIF>0); // close up switch statement
block|}
else|else
block|{
name|finishingInfo
operator|.
name|postscript
operator|=
name|ps
expr_stmt|;
name|finishingInfo
operator|.
name|generatedSwitch
operator|=
literal|false
expr_stmt|;
name|finishingInfo
operator|.
name|generatedAnIf
operator|=
name|nIF
operator|>
literal|0
expr_stmt|;
comment|// return new CSharpBlockFinishingInfo(ps, false,nIF>0);
block|}
return|return
name|finishingInfo
return|;
block|}
DECL|method|suitableForCaseExpression (Alternative a)
specifier|private
specifier|static
name|boolean
name|suitableForCaseExpression
parameter_list|(
name|Alternative
name|a
parameter_list|)
block|{
return|return
name|a
operator|.
name|lookaheadDepth
operator|==
literal|1
operator|&&
name|a
operator|.
name|semPred
operator|==
literal|null
operator|&&
operator|!
name|a
operator|.
name|cache
index|[
literal|1
index|]
operator|.
name|containsEpsilon
argument_list|()
operator|&&
name|a
operator|.
name|cache
index|[
literal|1
index|]
operator|.
name|fset
operator|.
name|degree
argument_list|()
operator|<=
name|caseSizeThreshold
return|;
block|}
comment|/** Generate code to link an element reference into the AST */
DECL|method|genElementAST (AlternativeElement el)
specifier|private
name|void
name|genElementAST
parameter_list|(
name|AlternativeElement
name|el
parameter_list|)
block|{
comment|// handle case where you're not building trees, but are in tree walker.
comment|// Just need to get labels set up.
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
operator|&&
operator|!
name|grammar
operator|.
name|buildAST
condition|)
block|{
name|String
name|elementRef
decl_stmt|;
name|String
name|astName
decl_stmt|;
comment|// Generate names and declarations of the AST variable(s)
if|if
condition|(
name|el
operator|.
name|getLabel
argument_list|()
operator|==
literal|null
condition|)
block|{
name|elementRef
operator|=
name|lt1Value
expr_stmt|;
comment|// Generate AST variables for unlabeled stuff
name|astName
operator|=
literal|"tmp"
operator|+
name|astVarNumber
operator|+
literal|"_AST"
expr_stmt|;
name|astVarNumber
operator|++
expr_stmt|;
comment|// Map the generated AST variable in the alternate
name|mapTreeVariable
argument_list|(
name|el
argument_list|,
name|astName
argument_list|)
expr_stmt|;
comment|// Generate an "input" AST variable also
name|println
argument_list|(
name|labeledElementASTType
operator|+
literal|" "
operator|+
name|astName
operator|+
literal|"_in = "
operator|+
name|elementRef
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
if|if
condition|(
name|grammar
operator|.
name|buildAST
operator|&&
name|syntacticPredLevel
operator|==
literal|0
condition|)
block|{
name|boolean
name|needASTDecl
init|=
operator|(
name|genAST
operator|&&
operator|(
name|el
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
operator|||
operator|(
name|el
operator|.
name|getAutoGenType
argument_list|()
operator|!=
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
operator|)
operator|)
decl_stmt|;
comment|// RK: if we have a grammar element always generate the decl
comment|// since some guy can access it from an action and we can't
comment|// peek ahead (well not without making a mess).
comment|// I'd prefer taking this out.
if|if
condition|(
name|el
operator|.
name|getAutoGenType
argument_list|()
operator|!=
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|&&
operator|(
name|el
operator|instanceof
name|TokenRefElement
operator|)
condition|)
name|needASTDecl
operator|=
literal|true
expr_stmt|;
name|boolean
name|doNoGuessTest
init|=
operator|(
name|grammar
operator|.
name|hasSyntacticPredicate
operator|&&
name|needASTDecl
operator|)
decl_stmt|;
name|String
name|elementRef
decl_stmt|;
name|String
name|astNameBase
decl_stmt|;
comment|// Generate names and declarations of the AST variable(s)
if|if
condition|(
name|el
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// if the element is labeled use that name...
name|elementRef
operator|=
name|el
operator|.
name|getLabel
argument_list|()
expr_stmt|;
name|astNameBase
operator|=
name|el
operator|.
name|getLabel
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// else generate a temporary name...
name|elementRef
operator|=
name|lt1Value
expr_stmt|;
comment|// Generate AST variables for unlabeled stuff
name|astNameBase
operator|=
literal|"tmp"
operator|+
name|astVarNumber
expr_stmt|;
name|astVarNumber
operator|++
expr_stmt|;
block|}
comment|// Generate the declaration if required.
if|if
condition|(
name|needASTDecl
condition|)
block|{
comment|// Generate the declaration
if|if
condition|(
name|el
operator|instanceof
name|GrammarAtom
condition|)
block|{
name|GrammarAtom
name|ga
init|=
operator|(
name|GrammarAtom
operator|)
name|el
decl_stmt|;
if|if
condition|(
name|ga
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|genASTDeclaration
argument_list|(
name|el
argument_list|,
name|astNameBase
argument_list|,
name|ga
operator|.
name|getASTNodeType
argument_list|()
argument_list|)
expr_stmt|;
comment|//println(ga.getASTNodeType()+" " + astName+" = null;");
block|}
else|else
block|{
name|genASTDeclaration
argument_list|(
name|el
argument_list|,
name|astNameBase
argument_list|,
name|labeledElementASTType
argument_list|)
expr_stmt|;
comment|//println(labeledElementASTType+" " + astName + " = null;");
block|}
block|}
else|else
block|{
name|genASTDeclaration
argument_list|(
name|el
argument_list|,
name|astNameBase
argument_list|,
name|labeledElementASTType
argument_list|)
expr_stmt|;
comment|//println(labeledElementASTType+" " + astName + " = null;");
block|}
block|}
comment|// for convenience..
name|String
name|astName
init|=
name|astNameBase
operator|+
literal|"_AST"
decl_stmt|;
comment|// Map the generated AST variable in the alternate
name|mapTreeVariable
argument_list|(
name|el
argument_list|,
name|astName
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
comment|// Generate an "input" AST variable also
name|println
argument_list|(
name|labeledElementASTType
operator|+
literal|" "
operator|+
name|astName
operator|+
literal|"_in = null;"
argument_list|)
expr_stmt|;
block|}
comment|// Enclose actions with !guessing
if|if
condition|(
name|doNoGuessTest
condition|)
block|{
comment|//println("if (0 == inputState.guessing)");
comment|//println("{");
comment|//tabs++;
block|}
comment|// if something has a label assume it will be used
comment|// so we must initialize the RefAST
if|if
condition|(
name|el
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|el
operator|instanceof
name|GrammarAtom
condition|)
block|{
name|println
argument_list|(
name|astName
operator|+
literal|" = "
operator|+
name|getASTCreateString
argument_list|(
operator|(
name|GrammarAtom
operator|)
name|el
argument_list|,
name|elementRef
argument_list|)
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
name|astName
operator|+
literal|" = "
operator|+
name|getASTCreateString
argument_list|(
name|elementRef
argument_list|)
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
block|}
comment|// if it has no label but a declaration exists initialize it.
if|if
condition|(
name|el
operator|.
name|getLabel
argument_list|()
operator|==
literal|null
operator|&&
name|needASTDecl
condition|)
block|{
name|elementRef
operator|=
name|lt1Value
expr_stmt|;
if|if
condition|(
name|el
operator|instanceof
name|GrammarAtom
condition|)
block|{
name|println
argument_list|(
name|astName
operator|+
literal|" = "
operator|+
name|getASTCreateString
argument_list|(
operator|(
name|GrammarAtom
operator|)
name|el
argument_list|,
name|elementRef
argument_list|)
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
name|astName
operator|+
literal|" = "
operator|+
name|getASTCreateString
argument_list|(
name|elementRef
argument_list|)
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
comment|// Map the generated AST variable in the alternate
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
comment|// set "input" AST variable also
name|println
argument_list|(
name|astName
operator|+
literal|"_in = "
operator|+
name|elementRef
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|genAST
condition|)
block|{
switch|switch
condition|(
name|el
operator|.
name|getAutoGenType
argument_list|()
condition|)
block|{
case|case
name|GrammarElement
operator|.
name|AUTO_GEN_NONE
case|:
if|if
condition|(
name|usingCustomAST
operator|||
operator|(
operator|(
name|el
operator|instanceof
name|GrammarAtom
operator|)
operator|&&
operator|(
operator|(
operator|(
name|GrammarAtom
operator|)
name|el
operator|)
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
operator|)
operator|)
condition|)
name|println
argument_list|(
literal|"astFactory.addASTChild(currentAST, (AST)"
operator|+
name|astName
operator|+
literal|");"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|"astFactory.addASTChild(currentAST, "
operator|+
name|astName
operator|+
literal|");"
argument_list|)
expr_stmt|;
break|break;
case|case
name|GrammarElement
operator|.
name|AUTO_GEN_CARET
case|:
if|if
condition|(
name|usingCustomAST
operator|||
operator|(
operator|(
name|el
operator|instanceof
name|GrammarAtom
operator|)
operator|&&
operator|(
operator|(
operator|(
name|GrammarAtom
operator|)
name|el
operator|)
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
operator|)
operator|)
condition|)
name|println
argument_list|(
literal|"astFactory.makeASTRoot(currentAST, (AST)"
operator|+
name|astName
operator|+
literal|");"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|"astFactory.makeASTRoot(currentAST, "
operator|+
name|astName
operator|+
literal|");"
argument_list|)
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
if|if
condition|(
name|doNoGuessTest
condition|)
block|{
comment|//tabs--;
comment|//println("}");
block|}
block|}
block|}
comment|/** Close the try block and generate catch phrases 	 * if the element has a labeled handler in the rule 	 */
DECL|method|genErrorCatchForElement (AlternativeElement el)
specifier|private
name|void
name|genErrorCatchForElement
parameter_list|(
name|AlternativeElement
name|el
parameter_list|)
block|{
if|if
condition|(
name|el
operator|.
name|getLabel
argument_list|()
operator|==
literal|null
condition|)
return|return;
name|String
name|r
init|=
name|el
operator|.
name|enclosingRuleName
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|r
operator|=
name|CodeGenerator
operator|.
name|encodeLexerRuleName
argument_list|(
name|el
operator|.
name|enclosingRuleName
argument_list|)
expr_stmt|;
block|}
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|grammar
operator|.
name|getSymbol
argument_list|(
name|r
argument_list|)
decl_stmt|;
if|if
condition|(
name|rs
operator|==
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Enclosing rule not found!"
argument_list|)
expr_stmt|;
block|}
name|ExceptionSpec
name|ex
init|=
name|rs
operator|.
name|block
operator|.
name|findExceptionSpec
argument_list|(
name|el
operator|.
name|getLabel
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|ex
operator|!=
literal|null
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|genErrorHandler
argument_list|(
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Generate the catch phrases for a user-specified error handler */
DECL|method|genErrorHandler (ExceptionSpec ex)
specifier|private
name|void
name|genErrorHandler
parameter_list|(
name|ExceptionSpec
name|ex
parameter_list|)
block|{
comment|// Each ExceptionHandler in the ExceptionSpec is a separate catch
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|ex
operator|.
name|handlers
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|ExceptionHandler
name|handler
init|=
operator|(
name|ExceptionHandler
operator|)
name|ex
operator|.
name|handlers
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// Generate catch phrase
name|println
argument_list|(
literal|"catch ("
operator|+
name|handler
operator|.
name|exceptionTypeAndName
operator|.
name|getText
argument_list|()
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|hasSyntacticPredicate
condition|)
block|{
name|println
argument_list|(
literal|"if (0 == inputState.guessing)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
comment|// When not guessing, execute user handler action
name|ActionTransInfo
name|tInfo
init|=
operator|new
name|ActionTransInfo
argument_list|()
decl_stmt|;
name|printAction
argument_list|(
name|processActionForSpecialSymbols
argument_list|(
name|handler
operator|.
name|action
operator|.
name|getText
argument_list|()
argument_list|,
name|handler
operator|.
name|action
operator|.
name|getLine
argument_list|()
argument_list|,
name|currentRule
argument_list|,
name|tInfo
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|hasSyntacticPredicate
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"else"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// When guessing, rethrow exception
comment|//println("throw " + extractIdOfAction(handler.exceptionTypeAndName) + ";");
name|println
argument_list|(
literal|"throw;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
comment|// Close catch phrase
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Generate a try { opening if the element has a labeled handler in the rule */
DECL|method|genErrorTryForElement (AlternativeElement el)
specifier|private
name|void
name|genErrorTryForElement
parameter_list|(
name|AlternativeElement
name|el
parameter_list|)
block|{
if|if
condition|(
name|el
operator|.
name|getLabel
argument_list|()
operator|==
literal|null
condition|)
return|return;
name|String
name|r
init|=
name|el
operator|.
name|enclosingRuleName
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|r
operator|=
name|CodeGenerator
operator|.
name|encodeLexerRuleName
argument_list|(
name|el
operator|.
name|enclosingRuleName
argument_list|)
expr_stmt|;
block|}
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|grammar
operator|.
name|getSymbol
argument_list|(
name|r
argument_list|)
decl_stmt|;
if|if
condition|(
name|rs
operator|==
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Enclosing rule not found!"
argument_list|)
expr_stmt|;
block|}
name|ExceptionSpec
name|ex
init|=
name|rs
operator|.
name|block
operator|.
name|findExceptionSpec
argument_list|(
name|el
operator|.
name|getLabel
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|ex
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"try   // for error handling"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
block|}
DECL|method|genASTDeclaration (AlternativeElement el)
specifier|protected
name|void
name|genASTDeclaration
parameter_list|(
name|AlternativeElement
name|el
parameter_list|)
block|{
name|genASTDeclaration
argument_list|(
name|el
argument_list|,
name|labeledElementASTType
argument_list|)
expr_stmt|;
block|}
DECL|method|genASTDeclaration (AlternativeElement el, String node_type)
specifier|protected
name|void
name|genASTDeclaration
parameter_list|(
name|AlternativeElement
name|el
parameter_list|,
name|String
name|node_type
parameter_list|)
block|{
name|genASTDeclaration
argument_list|(
name|el
argument_list|,
name|el
operator|.
name|getLabel
argument_list|()
argument_list|,
name|node_type
argument_list|)
expr_stmt|;
block|}
DECL|method|genASTDeclaration (AlternativeElement el, String var_name, String node_type)
specifier|protected
name|void
name|genASTDeclaration
parameter_list|(
name|AlternativeElement
name|el
parameter_list|,
name|String
name|var_name
parameter_list|,
name|String
name|node_type
parameter_list|)
block|{
comment|// already declared?
if|if
condition|(
name|declaredASTVariables
operator|.
name|contains
argument_list|(
name|el
argument_list|)
condition|)
return|return;
comment|// emit code
comment|//String s = StringUtils.stripFrontBack(node_type, "\"", "\"");
comment|//println(s + " " + var_name + "_AST = null;");
name|println
argument_list|(
name|node_type
operator|+
literal|" "
operator|+
name|var_name
operator|+
literal|"_AST = null;"
argument_list|)
expr_stmt|;
comment|// mark as declared
name|declaredASTVariables
operator|.
name|put
argument_list|(
name|el
argument_list|,
name|el
argument_list|)
expr_stmt|;
block|}
comment|/** Generate a header that is common to all CSharp files */
DECL|method|genHeader ()
specifier|protected
name|void
name|genHeader
parameter_list|()
block|{
name|println
argument_list|(
literal|"// $ANTLR "
operator|+
name|Tool
operator|.
name|version
operator|+
literal|": "
operator|+
literal|"\""
operator|+
name|antlrTool
operator|.
name|fileMinusPath
argument_list|(
name|antlrTool
operator|.
name|grammarFile
argument_list|)
operator|+
literal|"\""
operator|+
literal|" -> "
operator|+
literal|"\""
operator|+
name|grammar
operator|.
name|getClassName
argument_list|()
operator|+
literal|".cs\"$"
argument_list|)
expr_stmt|;
block|}
DECL|method|genLiteralsTest ()
specifier|private
name|void
name|genLiteralsTest
parameter_list|()
block|{
name|println
argument_list|(
literal|"_ttype = testLiteralsTable(_ttype);"
argument_list|)
expr_stmt|;
block|}
DECL|method|genLiteralsTestForPartialToken ()
specifier|private
name|void
name|genLiteralsTestForPartialToken
parameter_list|()
block|{
name|println
argument_list|(
literal|"_ttype = testLiteralsTable(text.ToString(_begin, text.Length-_begin), _ttype);"
argument_list|)
expr_stmt|;
block|}
DECL|method|genMatch (BitSet b)
specifier|protected
name|void
name|genMatch
parameter_list|(
name|BitSet
name|b
parameter_list|)
block|{ 	}
DECL|method|genMatch (GrammarAtom atom)
specifier|protected
name|void
name|genMatch
parameter_list|(
name|GrammarAtom
name|atom
parameter_list|)
block|{
if|if
condition|(
name|atom
operator|instanceof
name|StringLiteralElement
condition|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|genMatchUsingAtomText
argument_list|(
name|atom
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|genMatchUsingAtomTokenType
argument_list|(
name|atom
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|atom
operator|instanceof
name|CharLiteralElement
condition|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|genMatchUsingAtomText
argument_list|(
name|atom
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|antlrTool
operator|.
name|error
argument_list|(
literal|"cannot ref character literals in grammar: "
operator|+
name|atom
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|atom
operator|instanceof
name|TokenRefElement
condition|)
block|{
name|genMatchUsingAtomText
argument_list|(
name|atom
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|atom
operator|instanceof
name|WildcardElement
condition|)
block|{
name|gen
argument_list|(
operator|(
name|WildcardElement
operator|)
name|atom
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|genMatchUsingAtomText (GrammarAtom atom)
specifier|protected
name|void
name|genMatchUsingAtomText
parameter_list|(
name|GrammarAtom
name|atom
parameter_list|)
block|{
comment|// match() for trees needs the _t cursor
name|String
name|astArgs
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
if|if
condition|(
name|usingCustomAST
condition|)
name|astArgs
operator|=
literal|"(AST)_t,"
expr_stmt|;
else|else
name|astArgs
operator|=
literal|"_t,"
expr_stmt|;
block|}
comment|// if in lexer and ! on element, save buffer index to kill later
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
name|atom
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
condition|)
block|{
name|declareSaveIndexVariableIfNeeded
argument_list|()
expr_stmt|;
name|println
argument_list|(
literal|"_saveIndex = text.Length;"
argument_list|)
expr_stmt|;
block|}
name|print
argument_list|(
name|atom
operator|.
name|not
condition|?
literal|"matchNot("
else|:
literal|"match("
argument_list|)
expr_stmt|;
name|_print
argument_list|(
name|astArgs
argument_list|)
expr_stmt|;
comment|// print out what to match
if|if
condition|(
name|atom
operator|.
name|atomText
operator|.
name|equals
argument_list|(
literal|"EOF"
argument_list|)
condition|)
block|{
comment|// horrible hack to handle EOF case
name|_print
argument_list|(
literal|"Token.EOF_TYPE"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|_print
argument_list|(
name|atom
operator|.
name|atomText
argument_list|)
expr_stmt|;
block|}
name|_println
argument_list|(
literal|");"
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|&&
operator|(
operator|!
name|saveText
operator|||
name|atom
operator|.
name|getAutoGenType
argument_list|()
operator|==
name|GrammarElement
operator|.
name|AUTO_GEN_BANG
operator|)
condition|)
block|{
name|declareSaveIndexVariableIfNeeded
argument_list|()
expr_stmt|;
name|println
argument_list|(
literal|"text.Length = _saveIndex;"
argument_list|)
expr_stmt|;
comment|// kill text atom put in buffer
block|}
block|}
DECL|method|genMatchUsingAtomTokenType (GrammarAtom atom)
specifier|protected
name|void
name|genMatchUsingAtomTokenType
parameter_list|(
name|GrammarAtom
name|atom
parameter_list|)
block|{
comment|// match() for trees needs the _t cursor
name|String
name|astArgs
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
if|if
condition|(
name|usingCustomAST
condition|)
name|astArgs
operator|=
literal|"(AST)_t,"
expr_stmt|;
else|else
name|astArgs
operator|=
literal|"_t,"
expr_stmt|;
block|}
comment|// If the literal can be mangled, generate the symbolic constant instead
name|String
name|mangledName
init|=
literal|null
decl_stmt|;
name|String
name|s
init|=
name|astArgs
operator|+
name|getValueString
argument_list|(
name|atom
operator|.
name|getType
argument_list|()
argument_list|)
decl_stmt|;
comment|// matching
name|println
argument_list|(
operator|(
name|atom
operator|.
name|not
condition|?
literal|"matchNot("
else|:
literal|"match("
operator|)
operator|+
name|s
operator|+
literal|");"
argument_list|)
expr_stmt|;
block|}
comment|/** Generate the nextToken() rule.  nextToken() is a synthetic 	* lexer rule that is the implicit OR of all user-defined 	* lexer rules. 	*/
DECL|method|genNextToken ()
specifier|public
name|void
name|genNextToken
parameter_list|()
block|{
comment|// Are there any public rules?  If not, then just generate a
comment|// fake nextToken().
name|boolean
name|hasPublicRules
init|=
literal|false
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|grammar
operator|.
name|rules
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|grammar
operator|.
name|rules
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|rs
operator|.
name|isDefined
argument_list|()
operator|&&
name|rs
operator|.
name|access
operator|.
name|equals
argument_list|(
literal|"public"
argument_list|)
condition|)
block|{
name|hasPublicRules
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|hasPublicRules
condition|)
block|{
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"override public Token nextToken()\t\t\t//throws TokenStreamException"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"try"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"uponEOF();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"catch(CharStreamIOException csioe)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"throw new TokenStreamIOException(csioe.io);"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"catch(CharStreamException cse)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"throw new TokenStreamException(cse.Message);"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"return new CommonToken(Token.EOF_TYPE, \"\");"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Create the synthesized nextToken() rule
name|RuleBlock
name|nextTokenBlk
init|=
name|MakeGrammar
operator|.
name|createNextTokenRule
argument_list|(
name|grammar
argument_list|,
name|grammar
operator|.
name|rules
argument_list|,
literal|"nextToken"
argument_list|)
decl_stmt|;
comment|// Define the nextToken rule symbol
name|RuleSymbol
name|nextTokenRs
init|=
operator|new
name|RuleSymbol
argument_list|(
literal|"mnextToken"
argument_list|)
decl_stmt|;
name|nextTokenRs
operator|.
name|setDefined
argument_list|()
expr_stmt|;
name|nextTokenRs
operator|.
name|setBlock
argument_list|(
name|nextTokenBlk
argument_list|)
expr_stmt|;
name|nextTokenRs
operator|.
name|access
operator|=
literal|"private"
expr_stmt|;
name|grammar
operator|.
name|define
argument_list|(
name|nextTokenRs
argument_list|)
expr_stmt|;
comment|// Analyze the nextToken rule
name|boolean
name|ok
init|=
name|grammar
operator|.
name|theLLkAnalyzer
operator|.
name|deterministic
argument_list|(
name|nextTokenBlk
argument_list|)
decl_stmt|;
comment|// Generate the next token rule
name|String
name|filterRule
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|filterMode
condition|)
block|{
name|filterRule
operator|=
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|filterRule
expr_stmt|;
block|}
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"override public Token nextToken()\t\t\t//throws TokenStreamException"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"Token theRetToken = null;"
argument_list|)
expr_stmt|;
name|_println
argument_list|(
literal|"tryAgain:"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"for (;;)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"Token _token = null;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"int _ttype = Token.INVALID_TYPE;"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|filterMode
condition|)
block|{
name|println
argument_list|(
literal|"setCommitToPath(false);"
argument_list|)
expr_stmt|;
if|if
condition|(
name|filterRule
operator|!=
literal|null
condition|)
block|{
comment|// Here's a good place to ensure that the filter rule actually exists
if|if
condition|(
operator|!
name|grammar
operator|.
name|isDefined
argument_list|(
name|CodeGenerator
operator|.
name|encodeLexerRuleName
argument_list|(
name|filterRule
argument_list|)
argument_list|)
condition|)
block|{
name|grammar
operator|.
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Filter rule "
operator|+
name|filterRule
operator|+
literal|" does not exist in this lexer"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|grammar
operator|.
name|getSymbol
argument_list|(
name|CodeGenerator
operator|.
name|encodeLexerRuleName
argument_list|(
name|filterRule
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|rs
operator|.
name|isDefined
argument_list|()
condition|)
block|{
name|grammar
operator|.
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Filter rule "
operator|+
name|filterRule
operator|+
literal|" does not exist in this lexer"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|rs
operator|.
name|access
operator|.
name|equals
argument_list|(
literal|"public"
argument_list|)
condition|)
block|{
name|grammar
operator|.
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Filter rule "
operator|+
name|filterRule
operator|+
literal|" must be protected"
argument_list|)
expr_stmt|;
block|}
block|}
name|println
argument_list|(
literal|"int _m;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"_m = mark();"
argument_list|)
expr_stmt|;
block|}
block|}
name|println
argument_list|(
literal|"resetText();"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"try     // for char stream error handling"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate try around whole thing to trap scanner errors
name|println
argument_list|(
literal|"try     // for lexical error handling"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Test for public lexical rules with empty paths
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nextTokenBlk
operator|.
name|getAlternatives
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Alternative
name|a
init|=
name|nextTokenBlk
operator|.
name|getAlternativeAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|a
operator|.
name|cache
index|[
literal|1
index|]
operator|.
name|containsEpsilon
argument_list|()
condition|)
block|{
comment|//String r = a.head.toString();
name|RuleRefElement
name|rr
init|=
operator|(
name|RuleRefElement
operator|)
name|a
operator|.
name|head
decl_stmt|;
name|String
name|r
init|=
name|CodeGenerator
operator|.
name|decodeLexerRuleName
argument_list|(
name|rr
operator|.
name|targetRule
argument_list|)
decl_stmt|;
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"public lexical rule "
operator|+
name|r
operator|+
literal|" is optional (can match \"nothing\")"
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Generate the block
name|String
name|newline
init|=
name|System
operator|.
name|getProperty
argument_list|(
literal|"line.separator"
argument_list|)
decl_stmt|;
name|CSharpBlockFinishingInfo
name|howToFinish
init|=
name|genCommonBlock
argument_list|(
name|nextTokenBlk
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|String
name|errFinish
init|=
literal|"if (LA(1)==EOF_CHAR) { uponEOF(); returnToken_ = makeToken(Token.EOF_TYPE); }"
decl_stmt|;
name|errFinish
operator|+=
name|newline
operator|+
literal|"\t\t\t\t"
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|filterMode
condition|)
block|{
if|if
condition|(
name|filterRule
operator|==
literal|null
condition|)
block|{
comment|//kunle: errFinish += "else { consume(); continue tryAgain; }";
name|errFinish
operator|+=
literal|"\t\t\t\telse"
expr_stmt|;
name|errFinish
operator|+=
literal|"\t\t\t\t{"
expr_stmt|;
name|errFinish
operator|+=
literal|"\t\t\t\t\tconsume();"
expr_stmt|;
name|errFinish
operator|+=
literal|"\t\t\t\t\tgoto tryAgain;"
expr_stmt|;
name|errFinish
operator|+=
literal|"\t\t\t\t}"
expr_stmt|;
block|}
else|else
block|{
name|errFinish
operator|+=
literal|"\t\t\t\t\telse"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\t{"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\tcommit();"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\ttry {m"
operator|+
name|filterRule
operator|+
literal|"(false);}"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\tcatch(RecognitionException e)"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\t{"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\t	// catastrophic failure"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\t	reportError(e);"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\t	consume();"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\t}"
operator|+
name|newline
operator|+
literal|"\t\t\t\t\tgoto tryAgain;"
operator|+
name|newline
operator|+
literal|"\t\t\t\t}"
expr_stmt|;
block|}
block|}
else|else
block|{
name|errFinish
operator|+=
literal|"else {"
operator|+
name|throwNoViable
operator|+
literal|"}"
expr_stmt|;
block|}
name|genBlockFinish
argument_list|(
name|howToFinish
argument_list|,
name|errFinish
argument_list|)
expr_stmt|;
comment|// at this point a valid token has been matched, undo "mark" that was done
if|if
condition|(
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|filterMode
operator|&&
name|filterRule
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"commit();"
argument_list|)
expr_stmt|;
block|}
comment|// Generate literals test if desired
comment|// make sure _ttype is set first; note returnToken_ must be
comment|// non-null as the rule was required to create it.
name|println
argument_list|(
literal|"if ( null==returnToken_ ) goto tryAgain; // found SKIP token"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"_ttype = returnToken_.Type;"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|getTestLiterals
argument_list|()
condition|)
block|{
name|genLiteralsTest
argument_list|()
expr_stmt|;
block|}
comment|// return token created by rule reference in switch
name|println
argument_list|(
literal|"returnToken_.Type = _ttype;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"return returnToken_;"
argument_list|)
expr_stmt|;
comment|// Close try block
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"catch (RecognitionException e) {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
if|if
condition|(
operator|(
operator|(
name|LexerGrammar
operator|)
name|grammar
operator|)
operator|.
name|filterMode
condition|)
block|{
if|if
condition|(
name|filterRule
operator|==
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"if (!getCommitToPath())"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"consume();"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"goto tryAgain;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"if (!getCommitToPath())"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"rewind(_m);"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"resetText();"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"try {m"
operator|+
name|filterRule
operator|+
literal|"(false);}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"catch(RecognitionException ee) {"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	// horrendous failure: error in filter rule"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	reportError(ee);"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	consume();"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|//println("goto tryAgain;");
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"else"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|nextTokenBlk
operator|.
name|getDefaultErrorHandler
argument_list|()
condition|)
block|{
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"reportError(e);"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"consume();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// pass on to invoking routine
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"throw new TokenStreamRecognitionException(e);"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// close CharStreamException try
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"catch (CharStreamException cse) {"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	if ( cse is CharStreamIOException ) {"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"		throw new TokenStreamIOException(((CharStreamIOException)cse).io);"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	else {"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"		throw new TokenStreamException(cse.Message);"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"	}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// close for-loop
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// close method nextToken
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|/** Gen a named rule block. 	 * ASTs are generated for each element of an alternative unless 	 * the rule or the alternative have a '!' modifier. 	 * 	 * If an alternative defeats the default tree construction, it 	 * must set<rule>_AST to the root of the returned AST. 	 * 	 * Each alternative that does automatic tree construction, builds 	 * up root and child list pointers in an ASTPair structure. 	 * 	 * A rule finishes by setting the returnAST variable from the 	 * ASTPair. 	 * 	 * @param rule The name of the rule to generate 	 * @param startSymbol true if the rule is a start symbol (i.e., not referenced elsewhere) 	*/
DECL|method|genRule (RuleSymbol s, boolean startSymbol, int ruleNum, TokenManager tm)
specifier|public
name|void
name|genRule
parameter_list|(
name|RuleSymbol
name|s
parameter_list|,
name|boolean
name|startSymbol
parameter_list|,
name|int
name|ruleNum
parameter_list|,
name|TokenManager
name|tm
parameter_list|)
block|{
name|tabs
operator|=
literal|1
expr_stmt|;
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"genRule("
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|")"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|s
operator|.
name|isDefined
argument_list|()
condition|)
block|{
name|antlrTool
operator|.
name|error
argument_list|(
literal|"undefined rule: "
operator|+
name|s
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Generate rule return type, name, arguments
name|RuleBlock
name|rblk
init|=
name|s
operator|.
name|getBlock
argument_list|()
decl_stmt|;
name|currentRule
operator|=
name|rblk
expr_stmt|;
name|currentASTResult
operator|=
name|s
operator|.
name|getId
argument_list|()
expr_stmt|;
comment|// clear list of declared ast variables..
name|declaredASTVariables
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// Save the AST generation state, and set it to that of the rule
name|boolean
name|savegenAST
init|=
name|genAST
decl_stmt|;
name|genAST
operator|=
name|genAST
operator|&&
name|rblk
operator|.
name|getAutoGen
argument_list|()
expr_stmt|;
comment|// boolean oldsaveTest = saveText;
name|saveText
operator|=
name|rblk
operator|.
name|getAutoGen
argument_list|()
expr_stmt|;
comment|// print javadoc comment if any
if|if
condition|(
name|s
operator|.
name|comment
operator|!=
literal|null
condition|)
block|{
name|_println
argument_list|(
name|s
operator|.
name|comment
argument_list|)
expr_stmt|;
block|}
comment|// Gen method access and final qualifier
comment|//print(s.access + " final ");
name|print
argument_list|(
name|s
operator|.
name|access
operator|+
literal|" "
argument_list|)
expr_stmt|;
comment|// Gen method return type (note lexer return action set at rule creation)
if|if
condition|(
name|rblk
operator|.
name|returnAction
operator|!=
literal|null
condition|)
block|{
comment|// Has specified return value
name|_print
argument_list|(
name|extractTypeOfAction
argument_list|(
name|rblk
operator|.
name|returnAction
argument_list|,
name|rblk
operator|.
name|getLine
argument_list|()
argument_list|,
name|rblk
operator|.
name|getColumn
argument_list|()
argument_list|)
operator|+
literal|" "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// No specified return value
name|_print
argument_list|(
literal|"void "
argument_list|)
expr_stmt|;
block|}
comment|// Gen method name
name|_print
argument_list|(
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"("
argument_list|)
expr_stmt|;
comment|// Additional rule parameters common to all rules for this grammar
name|_print
argument_list|(
name|commonExtraParams
argument_list|)
expr_stmt|;
if|if
condition|(
name|commonExtraParams
operator|.
name|length
argument_list|()
operator|!=
literal|0
operator|&&
name|rblk
operator|.
name|argAction
operator|!=
literal|null
condition|)
block|{
name|_print
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
comment|// Gen arguments
if|if
condition|(
name|rblk
operator|.
name|argAction
operator|!=
literal|null
condition|)
block|{
comment|// Has specified arguments
name|_println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
name|rblk
operator|.
name|argAction
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|print
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// No specified arguments
name|_print
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
block|}
comment|// Gen throws clause and open curly
name|_print
argument_list|(
literal|" //throws "
operator|+
name|exceptionThrown
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|ParserGrammar
condition|)
block|{
name|_print
argument_list|(
literal|", TokenStreamException"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|_print
argument_list|(
literal|", CharStreamException, TokenStreamException"
argument_list|)
expr_stmt|;
block|}
comment|// Add user-defined exceptions unless lexer (for now)
if|if
condition|(
name|rblk
operator|.
name|throwsSpec
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|antlrTool
operator|.
name|error
argument_list|(
literal|"user-defined throws spec not allowed (yet) for lexer rule "
operator|+
name|rblk
operator|.
name|ruleName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|_print
argument_list|(
literal|", "
operator|+
name|rblk
operator|.
name|throwsSpec
argument_list|)
expr_stmt|;
block|}
block|}
name|_println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|_println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Convert return action to variable declaration
if|if
condition|(
name|rblk
operator|.
name|returnAction
operator|!=
literal|null
condition|)
name|println
argument_list|(
name|rblk
operator|.
name|returnAction
operator|+
literal|";"
argument_list|)
expr_stmt|;
comment|// print out definitions needed by rules for various grammar types
name|println
argument_list|(
name|commonLocalVars
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|traceRules
condition|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
if|if
condition|(
name|usingCustomAST
condition|)
name|println
argument_list|(
literal|"traceIn(\""
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"\",(AST)_t);"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|"traceIn(\""
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"\",_t);"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"traceIn(\""
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"\");"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
comment|// lexer rule default return value is the rule's token name
comment|// This is a horrible hack to support the built-in EOF lexer rule.
if|if
condition|(
name|s
operator|.
name|getId
argument_list|()
operator|.
name|equals
argument_list|(
literal|"mEOF"
argument_list|)
condition|)
name|println
argument_list|(
literal|"_ttype = Token.EOF_TYPE;"
argument_list|)
expr_stmt|;
else|else
name|println
argument_list|(
literal|"_ttype = "
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
operator|+
literal|";"
argument_list|)
expr_stmt|;
comment|// delay creation of _saveIndex until we need it OK?
name|bSaveIndexCreated
operator|=
literal|false
expr_stmt|;
comment|/* 			      println("boolean old_saveConsumedInput=saveConsumedInput;"); 			      if ( !rblk.getAutoGen() ) {		// turn off "save input" if ! on rule 			      println("saveConsumedInput=false;"); 			      } 			    */
block|}
comment|// if debugging, write code to mark entry to the rule
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
if|if
condition|(
name|grammar
operator|instanceof
name|ParserGrammar
condition|)
name|println
argument_list|(
literal|"fireEnterRule("
operator|+
name|ruleNum
operator|+
literal|",0);"
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
name|println
argument_list|(
literal|"fireEnterRule("
operator|+
name|ruleNum
operator|+
literal|",_ttype);"
argument_list|)
expr_stmt|;
comment|// Generate trace code if desired
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
operator|||
name|grammar
operator|.
name|traceRules
condition|)
block|{
name|println
argument_list|(
literal|"try { // debugging"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
comment|// Initialize AST variables
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
comment|// "Input" value for rule
name|println
argument_list|(
name|labeledElementASTType
operator|+
literal|" "
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"_AST_in = ("
operator|+
name|labeledElementASTType
operator|+
literal|")_t;"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
comment|// Parser member used to pass AST returns from rule invocations
name|println
argument_list|(
literal|"returnAST = null;"
argument_list|)
expr_stmt|;
comment|// Tracks AST construction
comment|// println("ASTPair currentAST = (inputState.guessing==0) ? new ASTPair() : null;");
name|println
argument_list|(
literal|"ASTPair currentAST = new ASTPair();"
argument_list|)
expr_stmt|;
comment|// User-settable return value for rule.
name|println
argument_list|(
name|labeledElementASTType
operator|+
literal|" "
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"_AST = null;"
argument_list|)
expr_stmt|;
block|}
name|genBlockPreamble
argument_list|(
name|rblk
argument_list|)
expr_stmt|;
name|genBlockInitAction
argument_list|(
name|rblk
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|// Search for an unlabeled exception specification attached to the rule
name|ExceptionSpec
name|unlabeledUserSpec
init|=
name|rblk
operator|.
name|findExceptionSpec
argument_list|(
literal|""
argument_list|)
decl_stmt|;
comment|// Generate try block around the entire rule for  error handling
if|if
condition|(
name|unlabeledUserSpec
operator|!=
literal|null
operator|||
name|rblk
operator|.
name|getDefaultErrorHandler
argument_list|()
condition|)
block|{
name|println
argument_list|(
literal|"try {      // for error handling"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
comment|// Generate the alternatives
if|if
condition|(
name|rblk
operator|.
name|alternatives
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|// One alternative -- use simple form
name|Alternative
name|alt
init|=
name|rblk
operator|.
name|getAlternativeAt
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|String
name|pred
init|=
name|alt
operator|.
name|semPred
decl_stmt|;
if|if
condition|(
name|pred
operator|!=
literal|null
condition|)
name|genSemPred
argument_list|(
name|pred
argument_list|,
name|currentRule
operator|.
name|line
argument_list|)
expr_stmt|;
if|if
condition|(
name|alt
operator|.
name|synPred
operator|!=
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Syntactic predicate ignored for single alternative"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|alt
operator|.
name|synPred
operator|.
name|getLine
argument_list|()
argument_list|,
name|alt
operator|.
name|synPred
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|genAlt
argument_list|(
name|alt
argument_list|,
name|rblk
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Multiple alternatives -- generate complex form
name|boolean
name|ok
init|=
name|grammar
operator|.
name|theLLkAnalyzer
operator|.
name|deterministic
argument_list|(
name|rblk
argument_list|)
decl_stmt|;
name|CSharpBlockFinishingInfo
name|howToFinish
init|=
name|genCommonBlock
argument_list|(
name|rblk
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|genBlockFinish
argument_list|(
name|howToFinish
argument_list|,
name|throwNoViable
argument_list|)
expr_stmt|;
block|}
comment|// Generate catch phrase for error handling
if|if
condition|(
name|unlabeledUserSpec
operator|!=
literal|null
operator|||
name|rblk
operator|.
name|getDefaultErrorHandler
argument_list|()
condition|)
block|{
comment|// Close the try block
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
comment|// Generate user-defined or default catch phrases
if|if
condition|(
name|unlabeledUserSpec
operator|!=
literal|null
condition|)
block|{
name|genErrorHandler
argument_list|(
name|unlabeledUserSpec
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|rblk
operator|.
name|getDefaultErrorHandler
argument_list|()
condition|)
block|{
comment|// Generate default catch phrase
name|println
argument_list|(
literal|"catch ("
operator|+
name|exceptionThrown
operator|+
literal|" ex)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Generate code to handle error if not guessing
if|if
condition|(
name|grammar
operator|.
name|hasSyntacticPredicate
condition|)
block|{
name|println
argument_list|(
literal|"if (0 == inputState.guessing)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
block|}
name|println
argument_list|(
literal|"reportError(ex);"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
operator|)
condition|)
block|{
comment|// Generate code to consume until token in k==1 follow set
name|Lookahead
name|follow
init|=
name|grammar
operator|.
name|theLLkAnalyzer
operator|.
name|FOLLOW
argument_list|(
literal|1
argument_list|,
name|rblk
operator|.
name|endNode
argument_list|)
decl_stmt|;
name|String
name|followSetName
init|=
name|getBitsetName
argument_list|(
name|markBitsetForGen
argument_list|(
name|follow
operator|.
name|fset
argument_list|)
argument_list|)
decl_stmt|;
name|println
argument_list|(
literal|"consume();"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"consumeUntil("
operator|+
name|followSetName
operator|+
literal|");"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Just consume one token
name|println
argument_list|(
literal|"if (null != _t)"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"_t = _t.getNextSibling();"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|.
name|hasSyntacticPredicate
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
comment|// When guessing, rethrow exception
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"else"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|//println("throw ex;");
name|println
argument_list|(
literal|"throw;"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
comment|// Close catch phrase
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
comment|// Squirrel away the AST "return" value
if|if
condition|(
name|grammar
operator|.
name|buildAST
condition|)
block|{
name|println
argument_list|(
literal|"returnAST = "
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"_AST;"
argument_list|)
expr_stmt|;
block|}
comment|// Set return tree value for tree walkers
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"retTree_ = _t;"
argument_list|)
expr_stmt|;
block|}
comment|// Generate literals test for lexer rules so marked
if|if
condition|(
name|rblk
operator|.
name|getTestLiterals
argument_list|()
condition|)
block|{
if|if
condition|(
name|s
operator|.
name|access
operator|.
name|equals
argument_list|(
literal|"protected"
argument_list|)
condition|)
block|{
name|genLiteralsTestForPartialToken
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|genLiteralsTest
argument_list|()
expr_stmt|;
block|}
block|}
comment|// if doing a lexer rule, dump code to create token if necessary
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"if (_createToken&& (null == _token)&& (_ttype != Token.SKIP))"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"_token = makeToken(_ttype);"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"_token.setText(text.ToString(_begin, text.Length-_begin));"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"returnToken_ = _token;"
argument_list|)
expr_stmt|;
block|}
comment|// Gen the return statement if there is one (lexer has hard-wired return action)
if|if
condition|(
name|rblk
operator|.
name|returnAction
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"return "
operator|+
name|extractIdOfAction
argument_list|(
name|rblk
operator|.
name|returnAction
argument_list|,
name|rblk
operator|.
name|getLine
argument_list|()
argument_list|,
name|rblk
operator|.
name|getColumn
argument_list|()
argument_list|)
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
operator|||
name|grammar
operator|.
name|traceRules
condition|)
block|{
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"finally"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{ // debugging"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// If debugging, generate calls to mark exit of rule
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
condition|)
if|if
condition|(
name|grammar
operator|instanceof
name|ParserGrammar
condition|)
name|println
argument_list|(
literal|"fireExitRule("
operator|+
name|ruleNum
operator|+
literal|",0);"
argument_list|)
expr_stmt|;
elseif|else
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
name|println
argument_list|(
literal|"fireExitRule("
operator|+
name|ruleNum
operator|+
literal|",_ttype);"
argument_list|)
expr_stmt|;
if|if
condition|(
name|grammar
operator|.
name|traceRules
condition|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"traceOut(\""
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"\",_t);"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"traceOut(\""
operator|+
name|s
operator|.
name|getId
argument_list|()
operator|+
literal|"\");"
argument_list|)
expr_stmt|;
block|}
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|// Restore the AST generation state
name|genAST
operator|=
name|savegenAST
expr_stmt|;
comment|// restore char save state
comment|// saveText = oldsaveTest;
block|}
DECL|method|GenRuleInvocation (RuleRefElement rr)
specifier|private
name|void
name|GenRuleInvocation
parameter_list|(
name|RuleRefElement
name|rr
parameter_list|)
block|{
comment|// dump rule name
name|_print
argument_list|(
name|rr
operator|.
name|targetRule
operator|+
literal|"("
argument_list|)
expr_stmt|;
comment|// lexers must tell rule if it should set returnToken_
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
comment|// if labeled, could access Token, so tell rule to create
if|if
condition|(
name|rr
operator|.
name|getLabel
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|_print
argument_list|(
literal|"true"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|_print
argument_list|(
literal|"false"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|commonExtraArgs
operator|.
name|length
argument_list|()
operator|!=
literal|0
operator|||
name|rr
operator|.
name|args
operator|!=
literal|null
condition|)
block|{
name|_print
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Extra arguments common to all rules for this grammar
name|_print
argument_list|(
name|commonExtraArgs
argument_list|)
expr_stmt|;
if|if
condition|(
name|commonExtraArgs
operator|.
name|length
argument_list|()
operator|!=
literal|0
operator|&&
name|rr
operator|.
name|args
operator|!=
literal|null
condition|)
block|{
name|_print
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
comment|// Process arguments to method, if any
name|RuleSymbol
name|rs
init|=
operator|(
name|RuleSymbol
operator|)
name|grammar
operator|.
name|getSymbol
argument_list|(
name|rr
operator|.
name|targetRule
argument_list|)
decl_stmt|;
if|if
condition|(
name|rr
operator|.
name|args
operator|!=
literal|null
condition|)
block|{
comment|// When not guessing, execute user arg action
name|ActionTransInfo
name|tInfo
init|=
operator|new
name|ActionTransInfo
argument_list|()
decl_stmt|;
name|String
name|args
init|=
name|processActionForSpecialSymbols
argument_list|(
name|rr
operator|.
name|args
argument_list|,
literal|0
argument_list|,
name|currentRule
argument_list|,
name|tInfo
argument_list|)
decl_stmt|;
if|if
condition|(
name|tInfo
operator|.
name|assignToRoot
operator|||
name|tInfo
operator|.
name|refRuleRoot
operator|!=
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Arguments of rule reference '"
operator|+
name|rr
operator|.
name|targetRule
operator|+
literal|"' cannot set or ref #"
operator|+
name|currentRule
operator|.
name|getRuleName
argument_list|()
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|_print
argument_list|(
name|args
argument_list|)
expr_stmt|;
comment|// Warn if the rule accepts no arguments
if|if
condition|(
name|rs
operator|.
name|block
operator|.
name|argAction
operator|==
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Rule '"
operator|+
name|rr
operator|.
name|targetRule
operator|+
literal|"' accepts no arguments"
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// For C++, no warning if rule has parameters, because there may be default
comment|// values for all of the parameters
if|if
condition|(
name|rs
operator|.
name|block
operator|.
name|argAction
operator|!=
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|warning
argument_list|(
literal|"Missing parameters on reference to rule "
operator|+
name|rr
operator|.
name|targetRule
argument_list|,
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|,
name|rr
operator|.
name|getLine
argument_list|()
argument_list|,
name|rr
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|_println
argument_list|(
literal|");"
argument_list|)
expr_stmt|;
comment|// move down to the first child while parsing
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"_t = retTree_;"
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|genSemPred (String pred, int line)
specifier|protected
name|void
name|genSemPred
parameter_list|(
name|String
name|pred
parameter_list|,
name|int
name|line
parameter_list|)
block|{
comment|// translate $ and # references
name|ActionTransInfo
name|tInfo
init|=
operator|new
name|ActionTransInfo
argument_list|()
decl_stmt|;
name|pred
operator|=
name|processActionForSpecialSymbols
argument_list|(
name|pred
argument_list|,
name|line
argument_list|,
name|currentRule
argument_list|,
name|tInfo
argument_list|)
expr_stmt|;
comment|// ignore translation info...we don't need to do anything with it.
name|String
name|escapedPred
init|=
name|charFormatter
operator|.
name|escapeString
argument_list|(
name|pred
argument_list|)
decl_stmt|;
comment|// if debugging, wrap the semantic predicate evaluation in a method
comment|// that can tell SemanticPredicateListeners the result
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
operator|&&
operator|(
operator|(
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
operator|||
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
operator|)
condition|)
name|pred
operator|=
literal|"fireSemanticPredicateEvaluated(antlr.debug.SemanticPredicateEvent.VALIDATING,"
operator|+
name|addSemPred
argument_list|(
name|escapedPred
argument_list|)
operator|+
literal|","
operator|+
name|pred
operator|+
literal|")"
expr_stmt|;
name|println
argument_list|(
literal|"if (!("
operator|+
name|pred
operator|+
literal|"))"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"  throw new SemanticException(\""
operator|+
name|escapedPred
operator|+
literal|"\");"
argument_list|)
expr_stmt|;
block|}
comment|/** Write an array of Strings which are the semantic predicate 	 *  expressions.  The debugger will reference them by number only 	 */
DECL|method|genSemPredMap ()
specifier|protected
name|void
name|genSemPredMap
parameter_list|()
block|{
name|Enumeration
name|e
init|=
name|semPreds
operator|.
name|elements
argument_list|()
decl_stmt|;
name|println
argument_list|(
literal|"private string[] _semPredNames = {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
while|while
condition|(
name|e
operator|.
name|hasMoreElements
argument_list|()
condition|)
name|println
argument_list|(
literal|"\""
operator|+
name|e
operator|.
name|nextElement
argument_list|()
operator|+
literal|"\","
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"};"
argument_list|)
expr_stmt|;
block|}
DECL|method|genSynPred (SynPredBlock blk, String lookaheadExpr)
specifier|protected
name|void
name|genSynPred
parameter_list|(
name|SynPredBlock
name|blk
parameter_list|,
name|String
name|lookaheadExpr
parameter_list|)
block|{
if|if
condition|(
name|DEBUG_CODE_GENERATOR
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"gen=>("
operator|+
name|blk
operator|+
literal|")"
argument_list|)
expr_stmt|;
comment|// Dump synpred result variable
name|println
argument_list|(
literal|"bool synPredMatched"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|" = false;"
argument_list|)
expr_stmt|;
comment|// Gen normal lookahead test
name|println
argument_list|(
literal|"if ("
operator|+
name|lookaheadExpr
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Save input state
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"AST __t"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|" = _t;"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"int _m"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|" = mark();"
argument_list|)
expr_stmt|;
block|}
comment|// Once inside the try, assume synpred works unless exception caught
name|println
argument_list|(
literal|"synPredMatched"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|" = true;"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"inputState.guessing++;"
argument_list|)
expr_stmt|;
comment|// if debugging, tell listeners that a synpred has started
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
operator|&&
operator|(
operator|(
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
operator|||
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
operator|)
condition|)
block|{
name|println
argument_list|(
literal|"fireSyntacticPredicateStarted();"
argument_list|)
expr_stmt|;
block|}
name|syntacticPredLevel
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"try {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|gen
argument_list|(
operator|(
name|AlternativeBlock
operator|)
name|blk
argument_list|)
expr_stmt|;
comment|// gen code to test predicate
name|tabs
operator|--
expr_stmt|;
comment|//println("System.out.println(\"pred "+blk+" succeeded\");");
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|//kunle: lose a few warnings cheaply
comment|//  println("catch (" + exceptionThrown + " pe)");
name|println
argument_list|(
literal|"catch ("
operator|+
name|exceptionThrown
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|println
argument_list|(
literal|"synPredMatched"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|" = false;"
argument_list|)
expr_stmt|;
comment|//println("System.out.println(\"pred "+blk+" failed\");");
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// Restore input state
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|println
argument_list|(
literal|"_t = __t"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"rewind(_m"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|");"
argument_list|)
expr_stmt|;
block|}
name|println
argument_list|(
literal|"inputState.guessing--;"
argument_list|)
expr_stmt|;
comment|// if debugging, tell listeners how the synpred turned out
if|if
condition|(
name|grammar
operator|.
name|debuggingOutput
operator|&&
operator|(
operator|(
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
operator|||
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|)
operator|)
condition|)
block|{
name|println
argument_list|(
literal|"if (synPredMatched"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|")"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"  fireSyntacticPredicateSucceeded();"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"else"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"  fireSyntacticPredicateFailed();"
argument_list|)
expr_stmt|;
block|}
name|syntacticPredLevel
operator|--
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
comment|// Close lookahead test
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
comment|// Test synred result
name|println
argument_list|(
literal|"if ( synPredMatched"
operator|+
name|blk
operator|.
name|ID
operator|+
literal|" )"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
block|}
comment|/** Generate a static array containing the names of the tokens, 	 * indexed by the token type values.  This static array is used 	 * to format error messages so that the token identifers or literal 	 * strings are displayed instead of the token numbers. 	 * 	 * If a lexical rule has a paraphrase, use it rather than the 	 * token label. 	 */
DECL|method|genTokenStrings ()
specifier|public
name|void
name|genTokenStrings
parameter_list|()
block|{
comment|// Generate a string for each token.  This creates a static
comment|// array of Strings indexed by token type.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"public static readonly string[] tokenNames_ = new string[] {"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Walk the token vocabulary and generate a Vector of strings
comment|// from the tokens.
name|Vector
name|v
init|=
name|grammar
operator|.
name|tokenManager
operator|.
name|getVocabulary
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|v
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|s
init|=
operator|(
name|String
operator|)
name|v
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|==
literal|null
condition|)
block|{
name|s
operator|=
literal|"<"
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|i
argument_list|)
operator|+
literal|">"
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|s
operator|.
name|startsWith
argument_list|(
literal|"\""
argument_list|)
operator|&&
operator|!
name|s
operator|.
name|startsWith
argument_list|(
literal|"<"
argument_list|)
condition|)
block|{
name|TokenSymbol
name|ts
init|=
operator|(
name|TokenSymbol
operator|)
name|grammar
operator|.
name|tokenManager
operator|.
name|getTokenSymbol
argument_list|(
name|s
argument_list|)
decl_stmt|;
if|if
condition|(
name|ts
operator|!=
literal|null
operator|&&
name|ts
operator|.
name|getParaphrase
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|s
operator|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|ts
operator|.
name|getParaphrase
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|s
operator|.
name|startsWith
argument_list|(
literal|"\""
argument_list|)
condition|)
block|{
name|s
operator|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|s
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
expr_stmt|;
block|}
name|print
argument_list|(
name|charFormatter
operator|.
name|literalString
argument_list|(
name|s
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|!=
name|v
operator|.
name|size
argument_list|()
operator|-
literal|1
condition|)
block|{
name|_print
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|_println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|// Close the string array initailizer
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"};"
argument_list|)
expr_stmt|;
block|}
comment|/** Generate the token types CSharp file */
DECL|method|genTokenTypes (TokenManager tm)
specifier|protected
name|void
name|genTokenTypes
parameter_list|(
name|TokenManager
name|tm
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Open the token output CSharp file and set the currentOutput stream
comment|// SAS: file open was moved to a method so a subclass can override
comment|//      This was mainly for the VAJ interface
name|setupOutput
argument_list|(
name|tm
operator|.
name|getName
argument_list|()
operator|+
name|TokenTypesFileSuffix
argument_list|)
expr_stmt|;
name|tabs
operator|=
literal|0
expr_stmt|;
comment|// Generate the header common to all CSharp files
name|genHeader
argument_list|()
expr_stmt|;
comment|// Do not use printAction because we assume tabs==0
name|println
argument_list|(
name|behavior
operator|.
name|getHeaderAction
argument_list|(
literal|""
argument_list|)
argument_list|)
expr_stmt|;
comment|// Generate the CSharp namespace declaration (if specified)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitDeclarations
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
comment|// Encapsulate the definitions in a class.  This has to be done as a class because
comment|// they are all constants and CSharp inteface  types cannot contain constants.
name|println
argument_list|(
literal|"public class "
operator|+
name|tm
operator|.
name|getName
argument_list|()
operator|+
name|TokenTypesFileSuffix
argument_list|)
expr_stmt|;
comment|//println("public class " + getTokenTypesClassName());
name|println
argument_list|(
literal|"{"
argument_list|)
expr_stmt|;
name|tabs
operator|++
expr_stmt|;
name|genTokenDefinitions
argument_list|(
name|tm
argument_list|)
expr_stmt|;
comment|// Close the interface
name|tabs
operator|--
expr_stmt|;
name|println
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|tabs
operator|--
expr_stmt|;
comment|// Generate the CSharp namespace closures (if required)
if|if
condition|(
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|.
name|emitClosures
argument_list|(
name|currentOutput
argument_list|)
expr_stmt|;
comment|// Close the tokens output file
name|currentOutput
operator|.
name|close
argument_list|()
expr_stmt|;
name|currentOutput
operator|=
literal|null
expr_stmt|;
name|exitIfError
argument_list|()
expr_stmt|;
block|}
DECL|method|genTokenDefinitions (TokenManager tm)
specifier|protected
name|void
name|genTokenDefinitions
parameter_list|(
name|TokenManager
name|tm
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Generate a definition for each token type
name|Vector
name|v
init|=
name|tm
operator|.
name|getVocabulary
argument_list|()
decl_stmt|;
comment|// Do special tokens manually
name|println
argument_list|(
literal|"public const int EOF = "
operator|+
name|Token
operator|.
name|EOF_TYPE
operator|+
literal|";"
argument_list|)
expr_stmt|;
name|println
argument_list|(
literal|"public const int NULL_TREE_LOOKAHEAD = "
operator|+
name|Token
operator|.
name|NULL_TREE_LOOKAHEAD
operator|+
literal|";"
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
name|Token
operator|.
name|MIN_USER_TYPE
init|;
name|i
operator|<
name|v
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|s
init|=
operator|(
name|String
operator|)
name|v
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|s
operator|.
name|startsWith
argument_list|(
literal|"\""
argument_list|)
condition|)
block|{
comment|// a string literal
name|StringLiteralSymbol
name|sl
init|=
operator|(
name|StringLiteralSymbol
operator|)
name|tm
operator|.
name|getTokenSymbol
argument_list|(
name|s
argument_list|)
decl_stmt|;
if|if
condition|(
name|sl
operator|==
literal|null
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"String literal "
operator|+
name|s
operator|+
literal|" not in symbol table"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|sl
operator|.
name|label
operator|!=
literal|null
condition|)
block|{
name|println
argument_list|(
literal|"public const int "
operator|+
name|sl
operator|.
name|label
operator|+
literal|" = "
operator|+
name|i
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|mangledName
init|=
name|mangleLiteral
argument_list|(
name|s
argument_list|)
decl_stmt|;
if|if
condition|(
name|mangledName
operator|!=
literal|null
condition|)
block|{
comment|// We were able to create a meaningful mangled token name
name|println
argument_list|(
literal|"public const int "
operator|+
name|mangledName
operator|+
literal|" = "
operator|+
name|i
operator|+
literal|";"
argument_list|)
expr_stmt|;
comment|// if no label specified, make the label equal to the mangled name
name|sl
operator|.
name|label
operator|=
name|mangledName
expr_stmt|;
block|}
else|else
block|{
name|println
argument_list|(
literal|"// "
operator|+
name|s
operator|+
literal|" = "
operator|+
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|s
operator|.
name|startsWith
argument_list|(
literal|"<"
argument_list|)
condition|)
block|{
name|println
argument_list|(
literal|"public const int "
operator|+
name|s
operator|+
literal|" = "
operator|+
name|i
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|/** Process a string for an simple expression for use in xx/action.g 	 * it is used to cast simple tokens/references to the right type for 	 * the generated language. Basically called for every element in 	 * the vector to getASTCreateString(vector V) 	 * @param str A String. 	 */
DECL|method|processStringForASTConstructor ( String str )
specifier|public
name|String
name|processStringForASTConstructor
parameter_list|(
name|String
name|str
parameter_list|)
block|{
comment|/* 		System.out.println("processStringForASTConstructor: str = "+str+ 		                   ", custom = "+(new Boolean(usingCustomAST)).toString()+ 		                   ", tree = "+(new Boolean((grammar instanceof TreeWalkerGrammar))).toString()+ 		                   ", parser = "+(new Boolean((grammar instanceof ParserGrammar))).toString()+ 		                   ", notDefined = "+(new Boolean((!(grammar.tokenManager.tokenDefined(str))))).toString() 		                   ); 		*/
if|if
condition|(
name|usingCustomAST
operator|&&
operator|(
operator|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
operator|)
operator|||
operator|(
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
operator|)
operator|&&
operator|!
operator|(
name|grammar
operator|.
name|tokenManager
operator|.
name|tokenDefined
argument_list|(
name|str
argument_list|)
operator|)
condition|)
block|{
comment|//System.out.println("processStringForASTConstructor: "+str+" with cast");
return|return
literal|"(AST)"
operator|+
name|str
return|;
block|}
else|else
block|{
comment|//System.out.println("processStringForASTConstructor: "+str);
return|return
name|str
return|;
block|}
block|}
comment|/** Get a string for an expression to generate creation of an AST subtree. 	  * @param v A Vector of String, where each element is an expression 	  *          in the target language yielding an AST node. 	  */
DECL|method|getASTCreateString (Vector v)
specifier|public
name|String
name|getASTCreateString
parameter_list|(
name|Vector
name|v
parameter_list|)
block|{
if|if
condition|(
name|v
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|""
return|;
block|}
name|StringBuffer
name|buf
init|=
operator|new
name|StringBuffer
argument_list|()
decl_stmt|;
name|buf
operator|.
name|append
argument_list|(
literal|"("
operator|+
name|labeledElementASTType
operator|+
literal|")astFactory.make( (new ASTArray("
operator|+
name|v
operator|.
name|size
argument_list|()
operator|+
literal|"))"
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|v
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|buf
operator|.
name|append
argument_list|(
literal|".add("
operator|+
name|v
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
name|buf
operator|.
name|append
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
return|return
name|buf
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/** Get a string for an expression to generate creating of an AST node 	 * @param atom The grammar node for which you are creating the node 	 * @param str The arguments to the AST constructor 	 */
DECL|method|getASTCreateString (GrammarAtom atom, String astCtorArgs)
specifier|public
name|String
name|getASTCreateString
parameter_list|(
name|GrammarAtom
name|atom
parameter_list|,
name|String
name|astCtorArgs
parameter_list|)
block|{
name|String
name|astCreateString
init|=
literal|"astFactory.create("
operator|+
name|astCtorArgs
operator|+
literal|")"
decl_stmt|;
if|if
condition|(
name|atom
operator|==
literal|null
condition|)
return|return
name|getASTCreateString
argument_list|(
name|astCtorArgs
argument_list|)
return|;
else|else
block|{
if|if
condition|(
name|atom
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// this Atom was instantiated from a Token that had an "AST" option - associating
comment|// it with a specific heterogeneous AST type - applied to either:
comment|// 1) it's underlying TokenSymbol (in the "tokens {} section" or,
comment|// 2) a particular token reference in the grammar
comment|//
comment|// For option (1), we simply generate a cast to hetero-AST type
comment|// For option (2), we generate a call to factory.create(Token, ASTNodeType) and cast it too
name|TokenSymbol
name|ts
init|=
name|grammar
operator|.
name|tokenManager
operator|.
name|getTokenSymbol
argument_list|(
name|atom
operator|.
name|getText
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|ts
operator|==
literal|null
operator|)
operator|||
operator|(
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|!=
name|atom
operator|.
name|getASTNodeType
argument_list|()
operator|)
condition|)
name|astCreateString
operator|=
literal|"("
operator|+
name|atom
operator|.
name|getASTNodeType
argument_list|()
operator|+
literal|") astFactory.create("
operator|+
name|astCtorArgs
operator|+
literal|", \""
operator|+
name|atom
operator|.
name|getASTNodeType
argument_list|()
operator|+
literal|"\")"
expr_stmt|;
elseif|else
if|if
condition|(
operator|(
name|ts
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|!=
literal|null
operator|)
condition|)
name|astCreateString
operator|=
literal|"("
operator|+
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|+
literal|") "
operator|+
name|astCreateString
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|usingCustomAST
condition|)
name|astCreateString
operator|=
literal|"("
operator|+
name|labeledElementASTType
operator|+
literal|") "
operator|+
name|astCreateString
expr_stmt|;
block|}
return|return
name|astCreateString
return|;
block|}
comment|/** Returns a string expression that creates an AST node using the specified      *  AST constructor argument string. 	 *  Parses the first (possibly only) argument in the supplied AST ctor argument 	 *	string to obtain the token type -- ctorID. 	 * 	 *  IF the token type is a valid token symbol AND 	 *	   it has an associated AST node type     AND 	 *	   this is not a #[ID, "T", "ASTType"] constructor 	 *	THEN 	 *	   generate a call to factory.create(ID, Text, token.ASTNodeType()) 	 * 	 *  #[ID, "T", "ASTType"] constructors are mapped to astFactory.create(ID, "T", "ASTType") 	 * 	 *  The supported AST constructor forms are: 	 *		#[ID] 	 *		#[ID, "text"] 	 *  	#[ID, "text", ASTclassname]	-- introduced in 2.7.2 	 *      * @param astCtorArgs The arguments to the AST constructor      */
DECL|method|getASTCreateString (String astCtorArgs)
specifier|public
name|String
name|getASTCreateString
parameter_list|(
name|String
name|astCtorArgs
parameter_list|)
block|{
comment|// kunle: 19-Aug-2002
comment|// This AST creation string is almost certainly[*1] a manual tree construction request.
comment|// From the manual [I couldn't read ALL of the code ;-)], this can only be one of:
comment|// 1) #[ID]                     -- 'astCtorArgs' contains: 'ID'                     (without quotes)    or,
comment|// 2) #[ID, "T"]                -- 'astCtorArgs' contains: 'ID, "Text"'             (without single quotes) or,
comment|// kunle: 08-Dec-2002 - 2.7.2a6
comment|// 3) #[ID, "T", "ASTTypeName"] -- 'astCtorArgs' contains: 'ID, "T", "ASTTypeName"' (without single quotes)
comment|//
comment|// [*1]  In my tests, 'atom' was '== null' only for manual tree construction requests
if|if
condition|(
name|astCtorArgs
operator|==
literal|null
condition|)
block|{
name|astCtorArgs
operator|=
literal|""
expr_stmt|;
block|}
name|String
name|astCreateString
init|=
literal|"astFactory.create("
operator|+
name|astCtorArgs
operator|+
literal|")"
decl_stmt|;
name|String
name|ctorID
init|=
name|astCtorArgs
decl_stmt|;
name|String
name|ctorText
init|=
literal|null
decl_stmt|;
name|int
name|commaIndex
decl_stmt|;
name|boolean
name|ctorIncludesCustomType
init|=
literal|false
decl_stmt|;
comment|// Is this a #[ID, "t", "ASTType"] constructor?
name|commaIndex
operator|=
name|astCtorArgs
operator|.
name|indexOf
argument_list|(
literal|','
argument_list|)
expr_stmt|;
if|if
condition|(
name|commaIndex
operator|!=
operator|-
literal|1
condition|)
block|{
name|ctorID
operator|=
name|astCtorArgs
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|commaIndex
argument_list|)
expr_stmt|;
comment|// the 'ID'   portion of #[ID, "Text"]
name|ctorText
operator|=
name|astCtorArgs
operator|.
name|substring
argument_list|(
name|commaIndex
operator|+
literal|1
argument_list|,
name|astCtorArgs
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
comment|// the 'Text' portion of #[ID, "Text"]
name|commaIndex
operator|=
name|ctorText
operator|.
name|indexOf
argument_list|(
literal|','
argument_list|)
expr_stmt|;
if|if
condition|(
name|commaIndex
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// This is an AST creation of the form: #[ID, "Text", "ASTTypename"]
comment|// Support for this was introduced with 2.7.2a6
comment|// create default type or (since 2.7.2) 3rd arg is classname
name|ctorIncludesCustomType
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|TokenSymbol
name|ts
init|=
name|grammar
operator|.
name|tokenManager
operator|.
name|getTokenSymbol
argument_list|(
name|ctorID
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
literal|null
operator|!=
name|ts
operator|)
operator|&&
operator|(
literal|null
operator|!=
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|)
condition|)
name|astCreateString
operator|=
literal|"("
operator|+
name|ts
operator|.
name|getASTNodeType
argument_list|()
operator|+
literal|") "
operator|+
name|astCreateString
expr_stmt|;
elseif|else
if|if
condition|(
name|usingCustomAST
condition|)
name|astCreateString
operator|=
literal|"("
operator|+
name|labeledElementASTType
operator|+
literal|") "
operator|+
name|astCreateString
expr_stmt|;
return|return
name|astCreateString
return|;
block|}
DECL|method|getLookaheadTestExpression (Lookahead[] look, int k)
specifier|protected
name|String
name|getLookaheadTestExpression
parameter_list|(
name|Lookahead
index|[]
name|look
parameter_list|,
name|int
name|k
parameter_list|)
block|{
name|StringBuffer
name|e
init|=
operator|new
name|StringBuffer
argument_list|(
literal|100
argument_list|)
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|e
operator|.
name|append
argument_list|(
literal|"("
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|k
condition|;
name|i
operator|++
control|)
block|{
name|BitSet
name|p
init|=
name|look
index|[
name|i
index|]
operator|.
name|fset
decl_stmt|;
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|e
operator|.
name|append
argument_list|(
literal|")&& ("
argument_list|)
expr_stmt|;
block|}
name|first
operator|=
literal|false
expr_stmt|;
comment|// Syn preds can yield<end-of-syn-pred> (epsilon) lookahead.
comment|// There is no way to predict what that token would be.  Just
comment|// allow anything instead.
if|if
condition|(
name|look
index|[
name|i
index|]
operator|.
name|containsEpsilon
argument_list|()
condition|)
block|{
name|e
operator|.
name|append
argument_list|(
literal|"true"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|e
operator|.
name|append
argument_list|(
name|getLookaheadTestTerm
argument_list|(
name|i
argument_list|,
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|e
operator|.
name|append
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
return|return
name|e
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**Generate a lookahead test expression for an alternate.  This 	 * will be a series of tests joined by '&&' and enclosed by '()', 	 * the number of such tests being determined by the depth of the lookahead. 	 */
DECL|method|getLookaheadTestExpression (Alternative alt, int maxDepth)
specifier|protected
name|String
name|getLookaheadTestExpression
parameter_list|(
name|Alternative
name|alt
parameter_list|,
name|int
name|maxDepth
parameter_list|)
block|{
name|int
name|depth
init|=
name|alt
operator|.
name|lookaheadDepth
decl_stmt|;
if|if
condition|(
name|depth
operator|==
name|GrammarAnalyzer
operator|.
name|NONDETERMINISTIC
condition|)
block|{
comment|// if the decision is nondeterministic, do the best we can: LL(k)
comment|// any predicates that are around will be generated later.
name|depth
operator|=
name|grammar
operator|.
name|maxk
expr_stmt|;
block|}
if|if
condition|(
name|maxDepth
operator|==
literal|0
condition|)
block|{
comment|// empty lookahead can result from alt with sem pred
comment|// that can see end of token.  E.g., A : {pred}? ('a')? ;
return|return
literal|"( true )"
return|;
block|}
return|return
literal|"("
operator|+
name|getLookaheadTestExpression
argument_list|(
name|alt
operator|.
name|cache
argument_list|,
name|depth
argument_list|)
operator|+
literal|")"
return|;
block|}
comment|/**Generate a depth==1 lookahead test expression given the BitSet. 	 * This may be one of: 	 * 1) a series of 'x==X||' tests 	 * 2) a range test using>=&&<= where possible, 	 * 3) a bitset membership test for complex comparisons 	 * @param k The lookahead level 	 * @param p The lookahead set for level k 	 */
DECL|method|getLookaheadTestTerm (int k, BitSet p)
specifier|protected
name|String
name|getLookaheadTestTerm
parameter_list|(
name|int
name|k
parameter_list|,
name|BitSet
name|p
parameter_list|)
block|{
comment|// Determine the name of the item to be compared
name|String
name|ts
init|=
name|lookaheadString
argument_list|(
name|k
argument_list|)
decl_stmt|;
comment|// Generate a range expression if possible
name|int
index|[]
name|elems
init|=
name|p
operator|.
name|toArray
argument_list|()
decl_stmt|;
if|if
condition|(
name|elementsAreRange
argument_list|(
name|elems
argument_list|)
condition|)
block|{
return|return
name|getRangeExpression
argument_list|(
name|k
argument_list|,
name|elems
argument_list|)
return|;
block|}
comment|// Generate a bitset membership test if possible
name|StringBuffer
name|e
decl_stmt|;
name|int
name|degree
init|=
name|p
operator|.
name|degree
argument_list|()
decl_stmt|;
if|if
condition|(
name|degree
operator|==
literal|0
condition|)
block|{
return|return
literal|"true"
return|;
block|}
if|if
condition|(
name|degree
operator|>=
name|bitsetTestThreshold
condition|)
block|{
name|int
name|bitsetIdx
init|=
name|markBitsetForGen
argument_list|(
name|p
argument_list|)
decl_stmt|;
return|return
name|getBitsetName
argument_list|(
name|bitsetIdx
argument_list|)
operator|+
literal|".member("
operator|+
name|ts
operator|+
literal|")"
return|;
block|}
comment|// Otherwise, generate the long-winded series of "x==X||" tests
name|e
operator|=
operator|new
name|StringBuffer
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|elems
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// Get the compared-to item (token or character value)
name|String
name|cs
init|=
name|getValueString
argument_list|(
name|elems
index|[
name|i
index|]
argument_list|)
decl_stmt|;
comment|// Generate the element comparison
if|if
condition|(
name|i
operator|>
literal|0
condition|)
name|e
operator|.
name|append
argument_list|(
literal|"||"
argument_list|)
expr_stmt|;
name|e
operator|.
name|append
argument_list|(
name|ts
argument_list|)
expr_stmt|;
name|e
operator|.
name|append
argument_list|(
literal|"=="
argument_list|)
expr_stmt|;
name|e
operator|.
name|append
argument_list|(
name|cs
argument_list|)
expr_stmt|;
block|}
return|return
name|e
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/** Return an expression for testing a contiguous renage of elements 	 * @param k The lookahead level 	 * @param elems The elements representing the set, usually from BitSet.toArray(). 	 * @return String containing test expression. 	 */
DECL|method|getRangeExpression (int k, int[] elems)
specifier|public
name|String
name|getRangeExpression
parameter_list|(
name|int
name|k
parameter_list|,
name|int
index|[]
name|elems
parameter_list|)
block|{
if|if
condition|(
operator|!
name|elementsAreRange
argument_list|(
name|elems
argument_list|)
condition|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"getRangeExpression called with non-range"
argument_list|)
expr_stmt|;
block|}
name|int
name|begin
init|=
name|elems
index|[
literal|0
index|]
decl_stmt|;
name|int
name|end
init|=
name|elems
index|[
name|elems
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
return|return
literal|"("
operator|+
name|lookaheadString
argument_list|(
name|k
argument_list|)
operator|+
literal|">= "
operator|+
name|getValueString
argument_list|(
name|begin
argument_list|)
operator|+
literal|"&& "
operator|+
name|lookaheadString
argument_list|(
name|k
argument_list|)
operator|+
literal|"<= "
operator|+
name|getValueString
argument_list|(
name|end
argument_list|)
operator|+
literal|")"
return|;
block|}
comment|/** getValueString: get a string representation of a token or char value 	 * @param value The token or char value 	 */
DECL|method|getValueString (int value)
specifier|private
name|String
name|getValueString
parameter_list|(
name|int
name|value
parameter_list|)
block|{
name|String
name|cs
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|cs
operator|=
name|charFormatter
operator|.
name|literalChar
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|TokenSymbol
name|ts
init|=
name|grammar
operator|.
name|tokenManager
operator|.
name|getTokenSymbolAt
argument_list|(
name|value
argument_list|)
decl_stmt|;
if|if
condition|(
name|ts
operator|==
literal|null
condition|)
block|{
return|return
literal|""
operator|+
name|value
return|;
comment|// return token type as string
comment|// antlrTool.panic("vocabulary for token type " + value + " is null");
block|}
name|String
name|tId
init|=
name|ts
operator|.
name|getId
argument_list|()
decl_stmt|;
if|if
condition|(
name|ts
operator|instanceof
name|StringLiteralSymbol
condition|)
block|{
comment|// if string literal, use predefined label if any
comment|// if no predefined, try to mangle into LITERAL_xxx.
comment|// if can't mangle, use int value as last resort
name|StringLiteralSymbol
name|sl
init|=
operator|(
name|StringLiteralSymbol
operator|)
name|ts
decl_stmt|;
name|String
name|label
init|=
name|sl
operator|.
name|getLabel
argument_list|()
decl_stmt|;
if|if
condition|(
name|label
operator|!=
literal|null
condition|)
block|{
name|cs
operator|=
name|label
expr_stmt|;
block|}
else|else
block|{
name|cs
operator|=
name|mangleLiteral
argument_list|(
name|tId
argument_list|)
expr_stmt|;
if|if
condition|(
name|cs
operator|==
literal|null
condition|)
block|{
name|cs
operator|=
name|String
operator|.
name|valueOf
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|cs
operator|=
name|tId
expr_stmt|;
block|}
block|}
return|return
name|cs
return|;
block|}
comment|/**Is the lookahead for this alt empty? */
DECL|method|lookaheadIsEmpty (Alternative alt, int maxDepth)
specifier|protected
name|boolean
name|lookaheadIsEmpty
parameter_list|(
name|Alternative
name|alt
parameter_list|,
name|int
name|maxDepth
parameter_list|)
block|{
name|int
name|depth
init|=
name|alt
operator|.
name|lookaheadDepth
decl_stmt|;
if|if
condition|(
name|depth
operator|==
name|GrammarAnalyzer
operator|.
name|NONDETERMINISTIC
condition|)
block|{
name|depth
operator|=
name|grammar
operator|.
name|maxk
expr_stmt|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|depth
operator|&&
name|i
operator|<=
name|maxDepth
condition|;
name|i
operator|++
control|)
block|{
name|BitSet
name|p
init|=
name|alt
operator|.
name|cache
index|[
name|i
index|]
operator|.
name|fset
decl_stmt|;
if|if
condition|(
name|p
operator|.
name|degree
argument_list|()
operator|!=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
DECL|method|lookaheadString (int k)
specifier|private
name|String
name|lookaheadString
parameter_list|(
name|int
name|k
parameter_list|)
block|{
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
return|return
literal|"_t.Type"
return|;
block|}
return|return
literal|"LA("
operator|+
name|k
operator|+
literal|")"
return|;
block|}
comment|/** Mangle a string literal into a meaningful token name.  This is 	  * only possible for literals that are all characters.  The resulting 	  * mangled literal name is literalsPrefix with the text of the literal 	  * appended. 	  * @return A string representing the mangled literal, or null if not possible. 	  */
DECL|method|mangleLiteral (String s)
specifier|private
name|String
name|mangleLiteral
parameter_list|(
name|String
name|s
parameter_list|)
block|{
name|String
name|mangled
init|=
name|antlrTool
operator|.
name|literalsPrefix
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|s
operator|.
name|length
argument_list|()
operator|-
literal|1
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|Character
operator|.
name|isLetter
argument_list|(
name|s
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
operator|&&
name|s
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
operator|!=
literal|'_'
condition|)
block|{
return|return
literal|null
return|;
block|}
name|mangled
operator|+=
name|s
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|antlrTool
operator|.
name|upperCaseMangledLiterals
condition|)
block|{
name|mangled
operator|=
name|mangled
operator|.
name|toUpperCase
argument_list|()
expr_stmt|;
block|}
return|return
name|mangled
return|;
block|}
comment|/** Map an identifier to it's corresponding tree-node variable. 	  * This is context-sensitive, depending on the rule and alternative 	  * being generated 	  * @param idParam The identifier name to map 	  * @return The mapped id (which may be the same as the input), or null if the mapping is invalid due to duplicates 	  */
DECL|method|mapTreeId (String idParam, ActionTransInfo transInfo)
specifier|public
name|String
name|mapTreeId
parameter_list|(
name|String
name|idParam
parameter_list|,
name|ActionTransInfo
name|transInfo
parameter_list|)
block|{
comment|// if not in an action of a rule, nothing to map.
if|if
condition|(
name|currentRule
operator|==
literal|null
condition|)
return|return
name|idParam
return|;
name|boolean
name|in_var
init|=
literal|false
decl_stmt|;
name|String
name|id
init|=
name|idParam
decl_stmt|;
if|if
condition|(
name|grammar
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
if|if
condition|(
operator|!
name|grammar
operator|.
name|buildAST
condition|)
block|{
name|in_var
operator|=
literal|true
expr_stmt|;
block|}
comment|// If the id ends with "_in", then map it to the input variable
elseif|else
if|if
condition|(
name|id
operator|.
name|length
argument_list|()
operator|>
literal|3
operator|&&
name|id
operator|.
name|lastIndexOf
argument_list|(
literal|"_in"
argument_list|)
operator|==
name|id
operator|.
name|length
argument_list|()
operator|-
literal|3
condition|)
block|{
comment|// Strip off the "_in"
name|id
operator|=
name|id
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|id
operator|.
name|length
argument_list|()
operator|-
literal|3
argument_list|)
expr_stmt|;
name|in_var
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|// Check the rule labels.  If id is a label, then the output
comment|// variable is label_AST, and the input variable is plain label.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|currentRule
operator|.
name|labeledElements
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|AlternativeElement
name|elt
init|=
operator|(
name|AlternativeElement
operator|)
name|currentRule
operator|.
name|labeledElements
operator|.
name|elementAt
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|elt
operator|.
name|getLabel
argument_list|()
operator|.
name|equals
argument_list|(
name|id
argument_list|)
condition|)
block|{
return|return
name|in_var
condition|?
name|id
else|:
name|id
operator|+
literal|"_AST"
return|;
block|}
block|}
comment|// Failing that, check the id-to-variable map for the alternative.
comment|// If the id is in the map, then output variable is the name in the
comment|// map, and input variable is name_in
name|String
name|s
init|=
operator|(
name|String
operator|)
name|treeVariableMap
operator|.
name|get
argument_list|(
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|s
operator|==
name|NONUNIQUE
condition|)
block|{
comment|// There is more than one element with this id
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Ambiguous reference to AST element "
operator|+
name|id
operator|+
literal|" in rule "
operator|+
name|currentRule
operator|.
name|getRuleName
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
elseif|else
if|if
condition|(
name|s
operator|.
name|equals
argument_list|(
name|currentRule
operator|.
name|getRuleName
argument_list|()
argument_list|)
condition|)
block|{
comment|// a recursive call to the enclosing rule is
comment|// ambiguous with the rule itself.
comment|//				if( in_var )
comment|//					System.out.println("returning null (rulename)");
name|antlrTool
operator|.
name|error
argument_list|(
literal|"Ambiguous reference to AST element "
operator|+
name|id
operator|+
literal|" in rule "
operator|+
name|currentRule
operator|.
name|getRuleName
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
else|else
block|{
return|return
name|in_var
condition|?
name|s
operator|+
literal|"_in"
else|:
name|s
return|;
block|}
block|}
comment|// Failing that, check the rule name itself.  Output variable
comment|// is rule_AST; input variable is rule_AST_in (treeparsers).
if|if
condition|(
name|id
operator|.
name|equals
argument_list|(
name|currentRule
operator|.
name|getRuleName
argument_list|()
argument_list|)
condition|)
block|{
name|String
name|r
init|=
name|in_var
condition|?
name|id
operator|+
literal|"_AST_in"
else|:
name|id
operator|+
literal|"_AST"
decl_stmt|;
if|if
condition|(
name|transInfo
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|in_var
condition|)
block|{
name|transInfo
operator|.
name|refRuleRoot
operator|=
name|r
expr_stmt|;
block|}
block|}
return|return
name|r
return|;
block|}
else|else
block|{
comment|// id does not map to anything -- return itself.
return|return
name|id
return|;
block|}
block|}
comment|/** Given an element and the name of an associated AST variable, 	  * create a mapping between the element "name" and the variable name. 	  */
DECL|method|mapTreeVariable (AlternativeElement e, String name)
specifier|private
name|void
name|mapTreeVariable
parameter_list|(
name|AlternativeElement
name|e
parameter_list|,
name|String
name|name
parameter_list|)
block|{
comment|// For tree elements, defer to the root
if|if
condition|(
name|e
operator|instanceof
name|TreeElement
condition|)
block|{
name|mapTreeVariable
argument_list|(
operator|(
operator|(
name|TreeElement
operator|)
name|e
operator|)
operator|.
name|root
argument_list|,
name|name
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Determine the name of the element, if any, for mapping purposes
name|String
name|elName
init|=
literal|null
decl_stmt|;
comment|// Don't map labeled items
if|if
condition|(
name|e
operator|.
name|getLabel
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|e
operator|instanceof
name|TokenRefElement
condition|)
block|{
comment|// use the token id
name|elName
operator|=
operator|(
operator|(
name|TokenRefElement
operator|)
name|e
operator|)
operator|.
name|atomText
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|e
operator|instanceof
name|RuleRefElement
condition|)
block|{
comment|// use the rule name
name|elName
operator|=
operator|(
operator|(
name|RuleRefElement
operator|)
name|e
operator|)
operator|.
name|targetRule
expr_stmt|;
block|}
block|}
comment|// Add the element to the tree variable map if it has a name
if|if
condition|(
name|elName
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|treeVariableMap
operator|.
name|get
argument_list|(
name|elName
argument_list|)
operator|!=
literal|null
condition|)
block|{
comment|// Name is already in the map -- mark it as duplicate
name|treeVariableMap
operator|.
name|remove
argument_list|(
name|elName
argument_list|)
expr_stmt|;
name|treeVariableMap
operator|.
name|put
argument_list|(
name|elName
argument_list|,
name|NONUNIQUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|treeVariableMap
operator|.
name|put
argument_list|(
name|elName
argument_list|,
name|name
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/** Lexically process tree-specifiers in the action.      *  This will replace #id and #(...) with the appropriate      *  function calls and/or variables.      */
DECL|method|processActionForSpecialSymbols (String actionStr, int line, RuleBlock currentRule, ActionTransInfo tInfo)
specifier|protected
name|String
name|processActionForSpecialSymbols
parameter_list|(
name|String
name|actionStr
parameter_list|,
name|int
name|line
parameter_list|,
name|RuleBlock
name|currentRule
parameter_list|,
name|ActionTransInfo
name|tInfo
parameter_list|)
block|{
if|if
condition|(
name|actionStr
operator|==
literal|null
operator|||
name|actionStr
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|null
return|;
comment|// The action trans info tells us (at the moment) whether an
comment|// assignment was done to the rule's tree root.
if|if
condition|(
name|grammar
operator|==
literal|null
condition|)
return|return
name|actionStr
return|;
comment|// see if we have anything to do...
if|if
condition|(
operator|(
name|grammar
operator|.
name|buildAST
operator|&&
name|actionStr
operator|.
name|indexOf
argument_list|(
literal|'#'
argument_list|)
operator|!=
operator|-
literal|1
operator|)
operator|||
name|grammar
operator|instanceof
name|TreeWalkerGrammar
operator|||
operator|(
operator|(
name|grammar
operator|instanceof
name|LexerGrammar
operator|||
name|grammar
operator|instanceof
name|ParserGrammar
operator|)
operator|&&
name|actionStr
operator|.
name|indexOf
argument_list|(
literal|'$'
argument_list|)
operator|!=
operator|-
literal|1
operator|)
condition|)
block|{
comment|// Create a lexer to read an action and return the translated version
name|antlr
operator|.
name|actions
operator|.
name|csharp
operator|.
name|ActionLexer
name|lexer
init|=
operator|new
name|antlr
operator|.
name|actions
operator|.
name|csharp
operator|.
name|ActionLexer
argument_list|(
name|actionStr
argument_list|,
name|currentRule
argument_list|,
name|this
argument_list|,
name|tInfo
argument_list|)
decl_stmt|;
name|lexer
operator|.
name|setLineOffset
argument_list|(
name|line
argument_list|)
expr_stmt|;
name|lexer
operator|.
name|setFilename
argument_list|(
name|grammar
operator|.
name|getFilename
argument_list|()
argument_list|)
expr_stmt|;
name|lexer
operator|.
name|setTool
argument_list|(
name|antlrTool
argument_list|)
expr_stmt|;
try|try
block|{
name|lexer
operator|.
name|mACTION
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|actionStr
operator|=
name|lexer
operator|.
name|getTokenObject
argument_list|()
operator|.
name|getText
argument_list|()
expr_stmt|;
comment|// System.out.println("action translated: "+actionStr);
comment|// System.out.println("trans info is "+tInfo);
block|}
catch|catch
parameter_list|(
name|RecognitionException
name|ex
parameter_list|)
block|{
name|lexer
operator|.
name|reportError
argument_list|(
name|ex
argument_list|)
expr_stmt|;
return|return
name|actionStr
return|;
block|}
catch|catch
parameter_list|(
name|TokenStreamException
name|tex
parameter_list|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Error reading action:"
operator|+
name|actionStr
argument_list|)
expr_stmt|;
return|return
name|actionStr
return|;
block|}
catch|catch
parameter_list|(
name|CharStreamException
name|io
parameter_list|)
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Error reading action:"
operator|+
name|actionStr
argument_list|)
expr_stmt|;
return|return
name|actionStr
return|;
block|}
block|}
return|return
name|actionStr
return|;
block|}
DECL|method|setupGrammarParameters (Grammar g)
specifier|private
name|void
name|setupGrammarParameters
parameter_list|(
name|Grammar
name|g
parameter_list|)
block|{
if|if
condition|(
name|g
operator|instanceof
name|ParserGrammar
operator|||
name|g
operator|instanceof
name|LexerGrammar
operator|||
name|g
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
comment|/* RK: options also have to be added to Grammar.java and for options 			 * on the file level entries have to be defined in 			 * DefineGrammarSymbols.java and passed around via 'globals' in antlrTool.java 			 */
if|if
condition|(
name|antlrTool
operator|.
name|nameSpace
operator|!=
literal|null
condition|)
name|nameSpace
operator|=
operator|new
name|CSharpNameSpace
argument_list|(
name|antlrTool
operator|.
name|nameSpace
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
comment|//genHashLines = antlrTool.genHashLines;
comment|/* let grammar level options override filelevel ones... 			 */
if|if
condition|(
name|g
operator|.
name|hasOption
argument_list|(
literal|"namespace"
argument_list|)
condition|)
block|{
name|Token
name|t
init|=
name|g
operator|.
name|getOption
argument_list|(
literal|"namespace"
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|nameSpace
operator|=
operator|new
name|CSharpNameSpace
argument_list|(
name|t
operator|.
name|getText
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* 			if( g.hasOption("genHashLines") ) { 				Token t = g.getOption("genHashLines"); 				if( t != null )  { 					String val = StringUtils.stripFrontBack(t.getText(),"\"","\""); 					genHashLines = val.equals("true"); 				} 			} 			*/
block|}
if|if
condition|(
name|g
operator|instanceof
name|ParserGrammar
condition|)
block|{
name|labeledElementASTType
operator|=
literal|"AST"
expr_stmt|;
if|if
condition|(
name|g
operator|.
name|hasOption
argument_list|(
literal|"ASTLabelType"
argument_list|)
condition|)
block|{
name|Token
name|tsuffix
init|=
name|g
operator|.
name|getOption
argument_list|(
literal|"ASTLabelType"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tsuffix
operator|!=
literal|null
condition|)
block|{
name|String
name|suffix
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tsuffix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|!=
literal|null
condition|)
block|{
name|usingCustomAST
operator|=
literal|true
expr_stmt|;
name|labeledElementASTType
operator|=
name|suffix
expr_stmt|;
block|}
block|}
block|}
name|labeledElementType
operator|=
literal|"Token "
expr_stmt|;
name|labeledElementInit
operator|=
literal|"null"
expr_stmt|;
name|commonExtraArgs
operator|=
literal|""
expr_stmt|;
name|commonExtraParams
operator|=
literal|""
expr_stmt|;
name|commonLocalVars
operator|=
literal|""
expr_stmt|;
name|lt1Value
operator|=
literal|"LT(1)"
expr_stmt|;
name|exceptionThrown
operator|=
literal|"RecognitionException"
expr_stmt|;
name|throwNoViable
operator|=
literal|"throw new NoViableAltException(LT(1), getFilename());"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|g
operator|instanceof
name|LexerGrammar
condition|)
block|{
name|labeledElementType
operator|=
literal|"char "
expr_stmt|;
name|labeledElementInit
operator|=
literal|"'\\0'"
expr_stmt|;
name|commonExtraArgs
operator|=
literal|""
expr_stmt|;
name|commonExtraParams
operator|=
literal|"bool _createToken"
expr_stmt|;
name|commonLocalVars
operator|=
literal|"int _ttype; Token _token=null; int _begin=text.Length;"
expr_stmt|;
name|lt1Value
operator|=
literal|"LA(1)"
expr_stmt|;
name|exceptionThrown
operator|=
literal|"RecognitionException"
expr_stmt|;
name|throwNoViable
operator|=
literal|"throw new NoViableAltForCharException((char)LA(1), getFilename(), getLine(), getColumn());"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|g
operator|instanceof
name|TreeWalkerGrammar
condition|)
block|{
name|labeledElementASTType
operator|=
literal|"AST"
expr_stmt|;
name|labeledElementType
operator|=
literal|"AST"
expr_stmt|;
if|if
condition|(
name|g
operator|.
name|hasOption
argument_list|(
literal|"ASTLabelType"
argument_list|)
condition|)
block|{
name|Token
name|tsuffix
init|=
name|g
operator|.
name|getOption
argument_list|(
literal|"ASTLabelType"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tsuffix
operator|!=
literal|null
condition|)
block|{
name|String
name|suffix
init|=
name|StringUtils
operator|.
name|stripFrontBack
argument_list|(
name|tsuffix
operator|.
name|getText
argument_list|()
argument_list|,
literal|"\""
argument_list|,
literal|"\""
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|!=
literal|null
condition|)
block|{
name|usingCustomAST
operator|=
literal|true
expr_stmt|;
name|labeledElementASTType
operator|=
name|suffix
expr_stmt|;
name|labeledElementType
operator|=
name|suffix
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|g
operator|.
name|hasOption
argument_list|(
literal|"ASTLabelType"
argument_list|)
condition|)
block|{
name|g
operator|.
name|setOption
argument_list|(
literal|"ASTLabelType"
argument_list|,
operator|new
name|Token
argument_list|(
name|ANTLRTokenTypes
operator|.
name|STRING_LITERAL
argument_list|,
literal|"AST"
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|labeledElementInit
operator|=
literal|"null"
expr_stmt|;
name|commonExtraArgs
operator|=
literal|"_t"
expr_stmt|;
name|commonExtraParams
operator|=
literal|"AST _t"
expr_stmt|;
name|commonLocalVars
operator|=
literal|""
expr_stmt|;
if|if
condition|(
name|usingCustomAST
condition|)
name|lt1Value
operator|=
literal|"(_t==ASTNULL) ? null : ("
operator|+
name|labeledElementASTType
operator|+
literal|")_t"
expr_stmt|;
else|else
name|lt1Value
operator|=
literal|"_t"
expr_stmt|;
name|exceptionThrown
operator|=
literal|"RecognitionException"
expr_stmt|;
name|throwNoViable
operator|=
literal|"throw new NoViableAltException(_t);"
expr_stmt|;
block|}
else|else
block|{
name|antlrTool
operator|.
name|panic
argument_list|(
literal|"Unknown grammar type"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** This method exists so a subclass, namely VAJCodeGenerator, 	 *  can open the file in its own evil way.  JavaCodeGenerator 	 *  simply opens a text file... 	 */
DECL|method|setupOutput (String className)
specifier|public
name|void
name|setupOutput
parameter_list|(
name|String
name|className
parameter_list|)
throws|throws
name|IOException
block|{
name|currentOutput
operator|=
name|antlrTool
operator|.
name|openOutputFile
argument_list|(
name|className
operator|+
literal|".cs"
argument_list|)
expr_stmt|;
block|}
comment|/** Helper method from Eric Smith's version of CSharpCodeGenerator.*/
DECL|method|OctalToUnicode (String str)
specifier|private
specifier|static
name|String
name|OctalToUnicode
parameter_list|(
name|String
name|str
parameter_list|)
block|{
comment|// only do any conversion if the string looks like "'\003'"
if|if
condition|(
operator|(
literal|4
operator|<=
name|str
operator|.
name|length
argument_list|()
operator|)
operator|&&
operator|(
literal|'\''
operator|==
name|str
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
operator|)
operator|&&
operator|(
literal|'\\'
operator|==
name|str
operator|.
name|charAt
argument_list|(
literal|1
argument_list|)
operator|)
operator|&&
operator|(
operator|(
literal|'0'
operator|<=
name|str
operator|.
name|charAt
argument_list|(
literal|2
argument_list|)
operator|)
operator|&&
operator|(
literal|'7'
operator|>=
name|str
operator|.
name|charAt
argument_list|(
literal|2
argument_list|)
operator|)
operator|)
operator|&&
operator|(
literal|'\''
operator|==
name|str
operator|.
name|charAt
argument_list|(
name|str
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
operator|)
condition|)
block|{
comment|// convert octal representation to decimal, then to hex
name|Integer
name|x
init|=
name|Integer
operator|.
name|valueOf
argument_list|(
name|str
operator|.
name|substring
argument_list|(
literal|2
argument_list|,
name|str
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|,
literal|8
argument_list|)
decl_stmt|;
return|return
literal|"'\\x"
operator|+
name|Integer
operator|.
name|toHexString
argument_list|(
name|x
operator|.
name|intValue
argument_list|()
argument_list|)
operator|+
literal|"'"
return|;
block|}
else|else
block|{
return|return
name|str
return|;
block|}
block|}
comment|/** Helper method that returns the name of the interface/class/enum type for 	    token type constants. 	 */
DECL|method|getTokenTypesClassName ()
specifier|public
name|String
name|getTokenTypesClassName
parameter_list|()
block|{
name|TokenManager
name|tm
init|=
name|grammar
operator|.
name|tokenManager
decl_stmt|;
return|return
operator|new
name|String
argument_list|(
name|tm
operator|.
name|getName
argument_list|()
operator|+
name|TokenTypesFileSuffix
argument_list|)
return|;
block|}
DECL|method|declareSaveIndexVariableIfNeeded ()
specifier|private
name|void
name|declareSaveIndexVariableIfNeeded
parameter_list|()
block|{
if|if
condition|(
operator|!
name|bSaveIndexCreated
condition|)
block|{
name|println
argument_list|(
literal|"int _saveIndex = 0;"
argument_list|)
expr_stmt|;
name|bSaveIndexCreated
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

